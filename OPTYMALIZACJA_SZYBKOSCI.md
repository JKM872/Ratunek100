# âš¡ OPTYMALIZACJA SZYBKOÅšCI SCRAPINGU

## ğŸ“Š OBECNA WYDAJNOÅšÄ†

- **Czas na mecz:** ~10 sekund
- **30 meczÃ³w:** ~5 minut
- **100 meczÃ³w:** ~17 minut

---

## ğŸš€ OPTYMALIZACJE (od najÅ‚atwiejszych)

### **POZIOM 1: Zmniejsz timeouty (ÅATWE)** â­

**Plik:** `livesport_h2h_scraper.py`

**Zmiana 1 (linia 428):**
```python
# BYÅO:
wait = WebDriverWait(driver, 8)
time.sleep(2.0)

# ZMIEÅƒ NA:
wait = WebDriverWait(driver, 5)  # -3s
time.sleep(1.0)                   # -1s
```

**Zmiana 2 (linia 439-442):**
```python
# BYÅO:
time.sleep(0.3)
time.sleep(0.3)

# ZMIEÅƒ NA:
time.sleep(0.1)  # -0.2s
time.sleep(0.1)  # -0.2s
```

**Wynik:** ~6-7s na mecz zamiast 10s âœ… **40% szybciej!**

---

### **POZIOM 2: WyÅ‚Ä…cz zbÄ™dne funkcje (ÅšREDNIE)**

**Opcja A: Pomijaj formÄ™ gdy nie potrzeba**
```bash
# JeÅ›li NIE uÅ¼ywasz --only-form-advantage, forma jest niepotrzebna
# MoÅ¼na jÄ… wyÅ‚Ä…czyÄ‡ dla szybszoÅ›ci
```

**Opcja B: Zmniejsz liczbÄ™ H2H**
```python
# Plik: livesport_h2h_scraper.py, linia ~211
# BYÅO:
match_rows[:5]  # Pobiera 5 meczÃ³w H2H

# ZMIEÅƒ NA:
match_rows[:3]  # Pobiera 3 mecze H2H (wystarczy dla 60%)
```

**Wynik:** Dodatkowe 1-2s oszczÄ™dnoÅ›ci na mecz

---

### **POZIOM 3: WielowÄ…tkowoÅ›Ä‡ (TRUDNE)** ğŸ”¥

**Przetwarzaj wiele meczÃ³w rÃ³wnoczeÅ›nie!**

**Nowy plik:** `scrape_parallel.py`
```python
from concurrent.futures import ThreadPoolExecutor, as_completed
from livesport_h2h_scraper import start_driver, process_match
import time

def process_match_wrapper(url, headless=True):
    """Wrapper dla wielowÄ…tkowoÅ›ci - kaÅ¼dy wÄ…tek ma wÅ‚asny driver"""
    driver = start_driver(headless=headless)
    try:
        result = process_match(url, driver)
        return result
    finally:
        driver.quit()

def scrape_parallel(urls, max_workers=3):
    """
    Przetwarza mecze rÃ³wnolegle.
    
    Args:
        urls: Lista URL-i meczÃ³w
        max_workers: Liczba rÃ³wnolegÅ‚ych przeglÄ…darek (2-4 optymalne)
    """
    results = []
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # Uruchom wszystkie zadania
        future_to_url = {
            executor.submit(process_match_wrapper, url): url 
            for url in urls
        }
        
        # Zbieraj wyniki w miarÄ™ ukoÅ„czenia
        for i, future in enumerate(as_completed(future_to_url), 1):
            url = future_to_url[future]
            try:
                result = future.result()
                results.append(result)
                print(f"[{i}/{len(urls)}] âœ… UkoÅ„czono: {url[:60]}...")
            except Exception as e:
                print(f"[{i}/{len(urls)}] âŒ BÅ‚Ä…d: {e}")
    
    return results

# UÅ¼ycie:
# urls = get_match_links_from_day(...)
# results = scrape_parallel(urls, max_workers=3)
```

**Wynik:** **3x szybciej!** (30 meczÃ³w w ~2 minuty zamiast 5)

âš ï¸ **Uwaga:** Wymaga wiÄ™cej RAM (3-4 przeglÄ…darki naraz)

---

### **POZIOM 4: Cache H2H (ZAAWANSOWANE)**

**Zapisuj H2H do cache aby nie pobieraÄ‡ ponownie**

```python
import json
import hashlib
from datetime import datetime, timedelta

CACHE_FILE = 'outputs/h2h_cache.json'
CACHE_EXPIRY_DAYS = 7  # Cache waÅ¼ny 7 dni

def get_cache_key(url):
    """Generuj unikalny klucz dla URL"""
    return hashlib.md5(url.encode()).hexdigest()

def load_cache():
    """ZaÅ‚aduj cache z pliku"""
    try:
        with open(CACHE_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return {}

def save_cache(cache):
    """Zapisz cache do pliku"""
    with open(CACHE_FILE, 'w', encoding='utf-8') as f:
        json.dump(cache, f, ensure_ascii=False, indent=2)

def get_cached_h2h(url):
    """Pobierz H2H z cache jeÅ›li dostÄ™pne i aktualne"""
    cache = load_cache()
    key = get_cache_key(url)
    
    if key in cache:
        cached = cache[key]
        cached_date = datetime.fromisoformat(cached['date'])
        
        # SprawdÅº czy cache nie wygasÅ‚
        if datetime.now() - cached_date < timedelta(days=CACHE_EXPIRY_DAYS):
            return cached['h2h']
    
    return None
```

**Wynik:** PowtÃ³rne scrapowanie tych samych meczÃ³w **instant!**

---

## ğŸ“Š PODSUMOWANIE OPTYMALIZACJI

| Metoda | TrudnoÅ›Ä‡ | Przyspieszenie | Czas (30 meczÃ³w) |
|--------|----------|----------------|------------------|
| OryginaÅ‚ | - | - | ~5 min |
| Zmniejsz timeout | â­ Åatwe | 40% | ~3 min |
| PomiÅ„ zbÄ™dne | â­â­ Åšrednie | 50% | ~2.5 min |
| WielowÄ…tkowoÅ›Ä‡ | â­â­â­ Trudne | 200% | ~1.5 min |
| Cache | â­â­â­â­ Zaawansowane | âˆ (dla powtÃ³rek) | ~10 sek |

---

## ğŸ¯ ZALECENIA

### **Dla poczÄ…tkujÄ…cych:**
UÅ¼yj **Poziom 1** (zmniejsz timeouty) - Å‚atwe i bezpieczne

### **Dla Å›rednio zaawansowanych:**
Dodaj **Poziom 2** (pomiÅ„ zbÄ™dne) + **Poziom 1**

### **Dla zaawansowanych:**
Implementuj **wielowÄ…tkowoÅ›Ä‡** (Poziom 3) - najwiÄ™ksze przyspieszenie!

---

## âš ï¸ UWAGI

1. **Za niskie timeouty** mogÄ… powodowaÄ‡ bÅ‚Ä™dy (strona nie zaÅ‚aduje siÄ™)
2. **WielowÄ…tkowoÅ›Ä‡** wymaga wiÄ™cej RAM (~500MB na przeglÄ…darkÄ™)
3. **Livesport moÅ¼e zablokowaÄ‡** przy zbyt wielu rÃ³wnolegÅ‚ych requestach (max 3-4)

---

**Autor:** AI Assistant  
**Data:** 23.10.2025

