"""
Skrypt do zbierania linkÃ³w do meczÃ³w z Livesport
UÅ¼ywany przez massive-scraping-parallel workflow
"""

import argparse
from livesport_h2h_scraper import start_driver, get_match_links_from_day

def main():
    parser = argparse.ArgumentParser(description='Zbierz linki do meczÃ³w')
    parser.add_argument('--date', required=True, help='Data YYYY-MM-DD')
    parser.add_argument('--sports', nargs='+', required=True, help='Lista sportÃ³w')
    parser.add_argument('--output', default='match_urls.txt', help='Plik wyjÅ›ciowy')
    parser.add_argument('--headless', action='store_true', help='Tryb headless')
    
    args = parser.parse_args()
    
    print(f'ğŸ” Zbieranie linkÃ³w dla: {", ".join(args.sports)}')
    print(f'ğŸ“… Data: {args.date}')
    
    driver = start_driver(headless=args.headless)
    
    try:
        urls = get_match_links_from_day(driver, args.date, sports=args.sports, leagues=None)
        
        print(f'\nâœ… Znaleziono {len(urls)} meczÃ³w')
        
        with open(args.output, 'w', encoding='utf-8') as f:
            for url in urls:
                f.write(url + '\n')
        
        print(f'ğŸ’¾ Zapisano do: {args.output}')
        
    finally:
        driver.quit()

if __name__ == '__main__':
    main()

