"""
Livesport H2H scraper - Multi-Sport Edition
-------------------------------------------
Cel: dla danego dnia zapisaÄ‡ do pliku CSV wydarzenia (mecze), w ktÃ³rych GOSPODARZE pokonali przeciwnikÃ³w co najmniej 2 razy w ostatnich 5 bezpoÅ›rednich spotkaniach (H2H).

Wspierane sporty:
- PiÅ‚ka noÅ¼na (football/soccer)
- KoszykÃ³wka (basketball)
- SiatkÃ³wka (volleyball)
- PiÅ‚ka rÄ™czna (handball)
- Rugby
- Hokej (hockey/ice-hockey)

Uwagi / zaÅ‚oÅ¼enia:
- ZakÅ‚adam, Å¼e "ostatnie 5" oznacza 5 ostatnich bezpoÅ›rednich spotkaÅ„ miÄ™dzy obiema druÅ¼ynami (H2H na stronie meczu).
- Skrypt pracuje w trzech trybach:
    * --urls  : przetwarza listÄ™ adresÃ³w URL meczÃ³w (plik tekstowy z jednÄ… liniÄ… = jeden URL)
    * --auto  : prÃ³buje zebraÄ‡ listÄ™ linkÃ³w do meczÃ³w z ogÃ³lnej strony dla danego dnia
    * --sport : automatycznie zbiera linki dla konkretnych sportÃ³w
- Strona Livesport jest mocno zaleÅ¼na od JS â€” skrypt uÅ¼ywa Selenium (Chrome/Chromedriver).
- Przestrzegaj robots.txt i Terms of Use. Skrypt ma opÃ³Åºnienia (sleep) i limit prÃ³b, ale uÅ¼ywanie go na duÅ¼ej skali wymaga uzyskania zgody od wÅ‚aÅ›ciciela serwisu.

Wymagania:
- Python 3.9+
- pip install selenium beautifulsoup4 pandas webdriver-manager
- Chrome i dopasowany chromedriver (webdriver-manager uÅ‚atwia instalacjÄ™)

Uruchomienie (przykÅ‚ady):
python livesport_h2h_scraper.py --mode urls --date 2025-10-05 --input match_urls.txt --headless
python livesport_h2h_scraper.py --mode auto --date 2025-10-05 --sports football basketball --headless
python livesport_h2h_scraper.py --mode auto --date 2025-10-05 --sports football --leagues ekstraklasa premier-league --headless

Plik wynikowy: outputs/livesport_h2h_YYYY-MM-DD.csv (lub z sufixem sportu)

"""

import argparse
import time
import os
import csv
import re
import json
import gc  # Garbage collector dla zarzÄ…dzania pamiÄ™ciÄ…
from datetime import datetime
from typing import List, Dict, Optional

import pandas as pd
from bs4 import BeautifulSoup

from selenium import webdriver

# âœ… V7: Supabase fallback for Polish bookmakers (geo-blocking workaround)
try:
    from supabase import create_client
    HAS_SUPABASE = True
except ImportError:
    HAS_SUPABASE = False
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException, TimeoutException, WebDriverException
from webdriver_manager.chrome import ChromeDriverManager

# Retry logic dla zwiÄ™kszenia niezawodnoÅ›ci API calls
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

# Import wÅ‚asnych moduÅ‚Ã³w
import over_under_analyzer

# Database Manager (opcjonalny - dla integracji z aplikacjÄ… webowÄ…)
try:
    from db_manager import MatchDatabase
    DB_AVAILABLE = True
except ImportError:
    DB_AVAILABLE = False
    print("âš ï¸ db_manager.py nie znaleziony - zapis do bazy danych wyÅ‚Ä…czony")


# ----------------------
# Helper / scraper code
# ----------------------

# Globalna zmienna kontrolujÄ…ca poziom szczegÃ³Å‚owoÅ›ci logÃ³w
VERBOSE = False  # DomyÅ›lnie wyÅ‚Ä…czone, wÅ‚Ä…czane przez --verbose

# Mapowanie sportÃ³w na URLe Livesport
SPORT_URLS = {
    'football': 'https://www.livesport.com/pl/pilka-nozna/',
    'soccer': 'https://www.livesport.com/pl/pilka-nozna/',
    'basketball': 'https://www.livesport.com/pl/koszykowka/',
    'volleyball': 'https://www.livesport.com/pl/siatkowka/',
    'handball': 'https://www.livesport.com/pl/pilka-reczna/',
    'rugby': 'https://www.livesport.com/pl/rugby/',
    'hockey': 'https://www.livesport.com/pl/hokej/',
    'ice-hockey': 'https://www.livesport.com/pl/hokej/',
    'tennis': 'https://www.livesport.com/pl/tenis/',
}

# Sporty indywidualne (inna logika kwalifikacji)
INDIVIDUAL_SPORTS = ['tennis']

# Popularne ligi dla kaÅ¼dego sportu (mapowanie slug -> nazwa)
POPULAR_LEAGUES = {
    'football': {
        'ekstraklasa': 'Ekstraklasa',
        'premier-league': 'Premier League',
        'la-liga': 'LaLiga',
        'bundesliga': 'Bundesliga',
        'serie-a': 'Serie A',
        'ligue-1': 'Ligue 1',
        'champions-league': 'Liga MistrzÃ³w',
        'europa-league': 'Liga Europy',
    },
    'basketball': {
        'nba': 'NBA',
        'euroleague': 'Euroliga',
        'energa-basket-liga': 'Energa Basket Liga',
        'pbl': 'Polska Liga KoszykÃ³wki',
    },
    'volleyball': {
        'plusliga': 'PlusLiga',
        'tauron-liga': 'Tauron Liga',
    },
    'handball': {
        'pgnig-superliga': 'PGNiG Superliga',
    },
    'rugby': {
        'premiership': 'Premiership',
        'top-14': 'Top 14',
    },
    'hockey': {
        'nhl': 'NHL',
        'khl': 'KHL',
    },
}

H2H_TAB_TEXT_OPTIONS = ["H2H", "Head-to-Head", "BezpoÅ›rednie", "BezpoÅ›rednie spotkania", "H2H"]


def start_driver(headless: bool = True) -> webdriver.Chrome:
    chrome_options = Options()
    if headless:
        chrome_options.add_argument("--headless=new")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument('--window-size=1920,1080')
    # human-like user-agent (you may rotate)
    chrome_options.add_argument(
        "--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    )

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)
    return driver


def click_h2h_tab(driver: webdriver.Chrome) -> None:
    """SprÃ³buj kliknÄ…Ä‡ zakÅ‚adkÄ™ H2H - sprawdzamy kilka wariantÃ³w tekstowych i atrybutÃ³w."""
    for text in H2H_TAB_TEXT_OPTIONS:
        try:
            # XPath contains text
            el = driver.find_element(By.XPATH, f"//a[contains(translate(normalize-space(.), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), '{text.lower()}')]")
            el.click()
            time.sleep(0.8)
            return
        except Exception:
            pass

    # fallback: look for element with data-tab or href containing 'h2h'
    try:
        el = driver.find_element(By.XPATH, "//a[contains(@href, 'h2h') or contains(@data-tab, 'h2h')]")
        el.click()
        time.sleep(0.8)
        return
    except Exception:
        pass

    # if nothing works, do nothing and hope content is already present


def parse_h2h_from_soup(soup: BeautifulSoup, home_team: str, debug_url: str = None) -> List[Dict]:
    """Parsuje sekcjÄ™ H2H i zwraca listÄ™ ostatnich spotkaÅ„ (do 5).
    Zwracany format: [{'date':..., 'home':..., 'away':..., 'score': 'x - y', 'winner': 'home'/'away'/'draw'}]
    """
    results = []

    # METODA 1: Szukaj sekcji H2H
    h2h_sections = soup.find_all('div', class_='h2h__section')
    
    if not h2h_sections:
        h2h_sections = soup.find_all('div', class_=re.compile(r'h2h'))
    
    if not h2h_sections:
        # METODA 2: Szukaj bezpoÅ›rednio wierszy H2H
        all_h2h_rows = soup.select('a.h2h__row, div.h2h__row, [class*="h2h__row"]')
        if all_h2h_rows:
            return _parse_h2h_rows(all_h2h_rows[:5], debug_url)
    
    # DEBUG: Zapisz HTML gdy brak H2H
    if not h2h_sections and debug_url:
        try:
            debug_file = 'outputs/debug_no_h2h.html'
            os.makedirs('outputs', exist_ok=True)
            with open(debug_file, 'w', encoding='utf-8') as f:
                f.write(f"<!-- DEBUG: Brak sekcji H2H dla URL: {debug_url} -->\n")
                f.write(str(soup.prettify()))
        except:
            pass
    
    # Szukaj sekcji "Pojedynki bezpoÅ›rednie"
    pojedynki_section = None
    for section in h2h_sections:
        text = section.get_text(" ", strip=True)
        if 'pojedynki' in text.lower() or 'bezpoÅ›rednie' in text.lower() or 'head' in text.lower():
            pojedynki_section = section
            break
    
    if not pojedynki_section and h2h_sections:
        pojedynki_section = h2h_sections[0]
    
    if not pojedynki_section:
        return results
    
    # ZnajdÅº wiersze z meczami - prÃ³buj rÃ³Å¼nych selektorÃ³w
    match_rows = pojedynki_section.select('a.h2h__row')
    if not match_rows:
        match_rows = pojedynki_section.select('div.h2h__row')
    if not match_rows:
        match_rows = pojedynki_section.select('[class*="h2h__row"]')
    if not match_rows:
        match_rows = pojedynki_section.select('a, div[class*="row"]')
    
    return _parse_h2h_rows(match_rows[:5], debug_url)


def _parse_h2h_rows(match_rows: list, debug_url: str = None) -> List[Dict]:
    """
    Pomocnicza funkcja do parsowania wierszy H2H.
    Wydzielona aby moÅ¼na byÅ‚o jej uÅ¼yÄ‡ z rÃ³Å¼nych miejsc.
    """
    results = []
    
    for idx, row in enumerate(match_rows, 1):
        try:
            # Data
            date_el = row.select_one('span.h2h__date, [class*="date"]')
            date = date_el.get_text(strip=True) if date_el else ''
            
            # Gospodarz - prÃ³buj rÃ³Å¼nych selektorÃ³w
            home = None
            home_selectors = [
                'span.h2h__homeParticipant span.h2h__participantInner',
                'span.h2h__homeParticipant',
                '[class*="homeParticipant"]',
            ]
            for selector in home_selectors:
                home_el = row.select_one(selector)
                if home_el:
                    home = home_el.get_text(strip=True)
                    if home:
                        break
            
            # GoÅ›Ä‡ - prÃ³buj rÃ³Å¼nych selektorÃ³w
            away = None
            away_selectors = [
                'span.h2h__awayParticipant span.h2h__participantInner',
                'span.h2h__awayParticipant',
                '[class*="awayParticipant"]',
            ]
            for selector in away_selectors:
                away_el = row.select_one(selector)
                if away_el:
                    away = away_el.get_text(strip=True)
                    if away:
                        break
            
            # Fallback: wyciÄ…gnij z tekstu
            if not home or not away:
                row_text = row.get_text(strip=True)
                teams_match = re.search(r'(.+?)\s+(?:-|vs|â€“)\s+(.+?)(?:\d|$)', row_text)
                if teams_match:
                    if not home:
                        home = teams_match.group(1).strip()
                    if not away:
                        away = teams_match.group(2).strip()
            
            # Wynik - prÃ³buj rÃ³Å¼nych metod
            score = ''
            winner = 'unknown'
            
            # Metoda 1: Standardowe selektory
            result_spans = row.select('span.h2h__result span, [class*="result"] span')
            if len(result_spans) >= 2:
                goals_home = result_spans[0].get_text(strip=True)
                goals_away = result_spans[1].get_text(strip=True)
                score = f"{goals_home}-{goals_away}"
                
                try:
                    gh = int(goals_home)
                    ga = int(goals_away)
                    winner = 'home' if gh > ga else ('away' if ga > gh else 'draw')
                except:
                    winner = 'unknown'
            
            # Metoda 2: Regex z caÅ‚ego tekstu
            if not score:
                row_text = row.get_text(strip=True)
                score_match = re.search(r'(\d+)\s*[:\-â€“â€”]\s*(\d+)', row_text)
                if score_match:
                    goals_home = score_match.group(1)
                    goals_away = score_match.group(2)
                    score = f"{goals_home}-{goals_away}"
                    
                    try:
                        gh = int(goals_home)
                        ga = int(goals_away)
                        winner = 'home' if gh > ga else ('away' if ga > gh else 'draw')
                    except:
                        winner = 'unknown'

            if home and away and score:
                results.append({
                    'date': date,
                    'home': home,
                    'away': away,
                    'score': score,
                    'winner': winner,
                    'raw': f"{date} {home} {score} {away}"
                })
        
        except Exception as e:
            continue

    return results


def process_match(url: str, driver: webdriver.Chrome, away_team_focus: bool = False, sport: str = None) -> Dict:
    """Odwiedza stronÄ™ meczu, otwiera H2H i zwraca informacjÄ™ we wÅ‚aÅ›ciwym formacie.
    
    Args:
        url: URL meczu
        driver: Selenium WebDriver
        away_team_focus: JeÅ›li True, liczy zwyciÄ™stwa GOÅšCI w H2H zamiast gospodarzy
        sport: Sport type (volleyball, handball, football, basketball, etc.) for dynamic betType
    """
    out = {
        'match_url': url,
        'home_team': None,
        'away_team': None,
        'match_time': None,
        'h2h_last5': [],
        'home_wins_in_h2h_last5': 0,
        'away_wins_in_h2h_last5': 0,  # NOWE: dla trybu away_team_focus
        'h2h_count': 0,
        'win_rate': 0.0,  # % wygranych gospodarzy/goÅ›ci w H2H (zaleÅ¼nie od trybu)
        'qualifies': False,
        'home_form': [],  # Forma gospodarzy: ['W', 'L', 'W', 'D', 'W']
        'away_form': [],  # Forma goÅ›ci: ['L', 'L', 'W', 'L', 'W']
        'home_odds': None,  # Kursy bukmacherskie (info dodatkowa)
        'away_odds': None,
        'focus_team': 'away' if away_team_focus else 'home',  # NOWE: ktÃ³ry tryb
    }

    # KLUCZOWE: Przekieruj URL na stronÄ™ H2H (zamiast szczegoly)
    # POPRAWKA: ObsÅ‚uga URL z parametrem ?mid=
    
    # WyciÄ…gnij czÄ™Å›Ä‡ bazowÄ… i parametry
    if '?' in url:
        base_url, params = url.split('?', 1)
        params = '?' + params
    else:
        base_url = url
        params = ''
    
    # UsuÅ„ koÅ„cowy slash jeÅ›li istnieje
    base_url = base_url.rstrip('/')
    
    # ZamieÅ„ /szczegoly/ na /h2h/ogolem/ lub dodaj /h2h/ogolem/
    if '/szczegoly' in base_url:
        base_url = base_url.replace('/szczegoly', '/h2h/ogolem')
    elif '/h2h/' not in base_url:
        base_url = base_url + '/h2h/ogolem'
    
    # PoÅ‚Ä…cz z powrotem: base_url + params
    h2h_url = base_url + params
    
    try:
        driver.get(h2h_url)
        
        # OPTYMALIZACJA: Czekaj tylko na kluczowe elementy (max 5s)
        try:
            wait = WebDriverWait(driver, 5)  # Zmniejszone z 8s na 5s
            # Czekaj aÅ¼ zaÅ‚aduje siÄ™ JAKAKOLWIEK zawartoÅ›Ä‡ H2H
            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div[class*="h2h"], section[class*="h2h"]')))
        except TimeoutException:
            pass  # Kontynuuj mimo timeout
        
        # KrÃ³tki dodatkowy czas na renderowanie (zredukowany z 2s na 1s)
        time.sleep(1.0)
        
        # Scroll raz w dÃ³Å‚ i raz w gÃ³rÄ™ (szybko)
        try:
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(0.15)  # Zmniejszone z 0.3s na 0.15s
            driver.execute_script("window.scrollTo(0, 0);")
            time.sleep(0.15)  # Zmniejszone z 0.3s na 0.15s
        except:
            pass
            
    except WebDriverException as e:
        print(f"   âŒ BÅ‚Ä…d: {e}")
        return out

    # pobierz tytuÅ‚ strony jako fallback na nazwy druzyn
    try:
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        # sprÃ³buj wyciÄ…gnÄ…Ä‡ nazwy druÅ¼yn z nagÅ‚Ã³wka
        title = soup.title.string if soup.title else ''
        if title:
            # tytuÅ‚ czÄ™sto ma formÄ™ "Home - Away" lub "Home vs Away"
            import re
            m = re.split(r"\s[-â€“â€”|]\s|\svs\s|\sv\s", title)
            if len(m) >= 2:
                out['home_team'] = m[0].strip()
                out['away_team'] = m[1].strip()
    except Exception:
        pass

    # NIE MUSIMY KLIKAÄ† H2H - juÅ¼ jesteÅ›my na stronie /h2h/ogolem/
    # ZawartoÅ›Ä‡ juÅ¼ zostaÅ‚a zaÅ‚adowana przez WebDriverWait powyÅ¼ej
    
    soup = BeautifulSoup(driver.page_source, 'html.parser')

    # try to extract team names from the page header - NOWE SELEKTORY
    try:
        # Nowa struktura Livesport (2025)
        home_el = soup.select_one("div.smv__participantRow.smv__homeParticipant a.participant__participantName")
        if not home_el:
            home_el = soup.select_one("a.participant__participantName")
        if home_el:
            out['home_team'] = home_el.get_text(strip=True)
    except Exception:
        pass

    try:
        away_el = soup.select_one("div.smv__participantRow.smv__awayParticipant a.participant__participantName")
        if not away_el:
            # Fallback: weÅº drugÄ… nazwÄ™ druÅ¼yny
            all_teams = soup.select("a.participant__participantName")
            if len(all_teams) >= 2:
                away_el = all_teams[1]
        if away_el:
            out['away_team'] = away_el.get_text(strip=True)
    except Exception:
        pass
    
    # WydobÄ…dÅº datÄ™ i godzinÄ™ meczu
    try:
        # Szukaj rÃ³Å¼nych moÅ¼liwych selektorÃ³w dla daty/czasu
        # PrÃ³ba 1: Element z czasem startu
        time_el = soup.select_one("div.duelParticipant__startTime")
        if time_el:
            out['match_time'] = time_el.get_text(strip=True)
        
        # PrÃ³ba 2: Z tytuÅ‚u strony (czÄ™sto zawiera datÄ™)
        if not out['match_time'] and soup.title:
            title = soup.title.string
            # Szukaj wzorca daty i czasu w tytule
            import re
            # Format: DD.MM.YYYY HH:MM lub podobne
            date_match = re.search(r'(\d{1,2}\.\d{1,2}\.\d{2,4})\s*(\d{1,2}:\d{2})?', title)
            if date_match:
                date_str = date_match.group(1)
                time_str = date_match.group(2) if date_match.group(2) else ''
                out['match_time'] = f"{date_str} {time_str}".strip()
        
        # PrÃ³ba 3: Z URL (moÅ¼e zawieraÄ‡ datÄ™)
        if not out['match_time']:
            # Czasem data jest w parametrach URL
            if 'date=' in h2h_url:
                import re
                date_param = re.search(r'date=([^&]+)', h2h_url)
                if date_param:
                    out['match_time'] = date_param.group(1)
    except Exception:
        pass

    # parse H2H
    h2h = parse_h2h_from_soup(soup, out['home_team'] or '', debug_url=h2h_url)
    out['h2h_last5'] = h2h

    # count home AND away wins in H2H list
    # WAÅ»NE: W zaleÅ¼noÅ›ci od trybu (away_team_focus), liczymy zwyciÄ™stwa gospodarzy lub goÅ›ci
    cnt_home = 0
    cnt_away = 0
    current_home = out['home_team']
    current_away = out['away_team']
    
    for item in h2h:
        try:
            # Pobierz nazwy druÅ¼yn i wynik z H2H meczu
            h2h_home = item.get('home', '').strip()
            h2h_away = item.get('away', '').strip()
            score = item.get('score', '')
            
            # Parsuj wynik
            import re
            score_match = re.search(r"(\d+)\s*[:\-]\s*(\d+)", score)
            if not score_match:
                continue
            
            goals_home_side = int(score_match.group(1))
            goals_away_side = int(score_match.group(2))
            
            # SprawdÅº ktÃ³ry zespÃ³Å‚ wygraÅ‚ w tamtym meczu H2H
            if goals_home_side > goals_away_side:
                winner_team = h2h_home
            elif goals_away_side > goals_home_side:
                winner_team = h2h_away
            else:
                winner_team = None  # remis
            
            # Teraz sprawdÅº czy zwyciÄ™zcÄ… byÅ‚ AKTUALNY GOSPODARZ
            if winner_team and current_home:
                winner_normalized = winner_team.lower().strip()
                current_home_normalized = current_home.lower().strip()
                
                if (winner_normalized == current_home_normalized or 
                    winner_normalized in current_home_normalized or 
                    current_home_normalized in winner_normalized):
                    cnt_home += 1
            
            # Teraz sprawdÅº czy zwyciÄ™zcÄ… byli AKTUALNI GOÅšCIE
            if winner_team and current_away:
                winner_normalized = winner_team.lower().strip()
                current_away_normalized = current_away.lower().strip()
                
                if (winner_normalized == current_away_normalized or 
                    winner_normalized in current_away_normalized or 
                    current_away_normalized in winner_normalized):
                    cnt_away += 1
                    
        except Exception as e:
            # Fallback: uÅ¼yj starej heurystyki
            if item.get('winner') == 'home' and current_home:
                h2h_home = item.get('home', '').lower().strip()
                if current_home.lower().strip() in h2h_home or h2h_home in current_home.lower().strip():
                    cnt_home += 1
            if item.get('winner') == 'away' and current_away:
                h2h_away = item.get('away', '').lower().strip()
                if current_away.lower().strip() in h2h_away or h2h_away in current_away.lower().strip():
                    cnt_away += 1

    out['home_wins_in_h2h_last5'] = cnt_home
    out['away_wins_in_h2h_last5'] = cnt_away
    out['h2h_count'] = len(h2h)
    
    # NOWE KRYTERIUM: W zaleÅ¼noÅ›ci od trybu, sprawdzamy gospodarzy lub goÅ›ci
    if away_team_focus:
        # Tryb GOÅšCIE: GoÅ›cie wygrali â‰¥60% meczÃ³w H2H
        win_rate = (cnt_away / len(h2h)) if len(h2h) > 0 else 0.0
        out['win_rate'] = win_rate
        basic_qualifies = win_rate >= 0.60 and len(h2h) >= 1
    else:
        # Tryb GOSPODARZE (domyÅ›lny): Gospodarze wygrali â‰¥60% meczÃ³w H2H
        win_rate = (cnt_home / len(h2h)) if len(h2h) > 0 else 0.0
        out['win_rate'] = win_rate
        basic_qualifies = win_rate >= 0.60 and len(h2h) >= 1
    
    # FORMA DRUÅ»YN: Dodaj pola dla zaawansowanej analizy
    out['home_form'] = []  # Forma ogÃ³lna (stara metoda)
    out['away_form'] = []
    out['home_form_overall'] = []  # NOWE: Forma z H2H overall
    out['home_form_home'] = []     # NOWE: Forma u siebie
    out['away_form_overall'] = []  # NOWE: Forma z H2H overall
    out['away_form_away'] = []     # NOWE: Forma na wyjeÅºdzie
    out['form_advantage'] = False  # NOWE: Czy gospodarze majÄ… przewagÄ™ formy?
    
    # JEÅšLI PODSTAWOWO SIÄ˜ KWALIFIKUJE - sprawdÅº zaawansowanÄ… formÄ™
    if basic_qualifies:
        team_name = out['away_team'] if away_team_focus else out['home_team']
        print(f"   ðŸ“Š Podstawowo kwalifikuje ({'GOÅšCIE' if away_team_focus else 'GOSPODARZE'}: {team_name}, H2H: {win_rate*100:.0f}%) - sprawdzam formÄ™...")
        try:
            # ZAAWANSOWANA ANALIZA FORMY (3 ÅºrÃ³dÅ‚a)
            advanced_form = extract_advanced_team_form(url, driver)
            
            out['home_form_overall'] = advanced_form['home_form_overall']
            out['home_form_home'] = advanced_form['home_form_home']
            out['away_form_overall'] = advanced_form['away_form_overall']
            out['away_form_away'] = advanced_form['away_form_away']
            
            # W trybie away_team_focus, przewaga formy to GOÅšCIE w dobrej formie i GOSPODARZE w sÅ‚abej
            if away_team_focus:
                out['form_advantage'] = advanced_form.get('away_advantage', False)
            else:
                out['form_advantage'] = advanced_form['form_advantage']
            
            # Dla kompatybilnoÅ›ci wstecznej - ustaw starÄ… formÄ™
            out['home_form'] = advanced_form['home_form_overall']
            out['away_form'] = advanced_form['away_form_overall']
            
            # FINALNE KRYTERIUM: H2H â‰¥60% (podstawowe)
            # Forma jest BONUSEM (dodatkowa ikona ðŸ”¥), nie wymogiem
            out['qualifies'] = basic_qualifies
            
            if out['form_advantage']:
                if away_team_focus:
                    print(f"   âœ… KWALIFIKUJE + PRZEWAGA FORMY GOÅšCI! ðŸ”¥")
                else:
                    print(f"   âœ… KWALIFIKUJE + PRZEWAGA FORMY GOSPODARZY! ðŸ”¥")
                print(f"      Home ogÃ³Å‚em: {format_form(advanced_form['home_form_overall'])}")
                print(f"      Home u siebie: {format_form(advanced_form['home_form_home'])}")
                print(f"      Away ogÃ³Å‚em: {format_form(advanced_form['away_form_overall'])}")
                print(f"      Away na wyjeÅºdzie: {format_form(advanced_form['away_form_away'])}")
            elif advanced_form['home_form_overall'] or advanced_form['away_form_overall']:
                print(f"   âœ… KWALIFIKUJE (forma dostÄ™pna, ale brak przewagi)")
                print(f"      Home ogÃ³Å‚em: {format_form(advanced_form['home_form_overall'])}")
                print(f"      Away ogÃ³Å‚em: {format_form(advanced_form['away_form_overall'])}")
            else:
                print(f"   âœ… KWALIFIKUJE (brak danych formy - tylko H2H)")
                
        except Exception as e:
            print(f"   âš ï¸ BÅ‚Ä…d analizy formy: {e}")
            # Fallback - uÅ¼ywamy starego kryterium
            out['qualifies'] = basic_qualifies
            # Pobierz formÄ™ starÄ… metodÄ…
            try:
                home_form = extract_team_form(soup, driver, 'home', out.get('home_team'))
                away_form = extract_team_form(soup, driver, 'away', out.get('away_team'))
                out['home_form'] = home_form
                out['away_form'] = away_form
            except:
                pass
    else:
        # Nie kwalifikuje siÄ™ podstawowo - nie sprawdzaj formy
        out['qualifies'] = False
    
    # Kursy bukmacherskie - dodatkowa informacja (NIE wpÅ‚ywa na scoring!)
    # UÅ»YWAMY PRAWDZIWEGO API LIVESPORT z MULTI-BOOKMAKER SUPPORT!
    # V4: Dodano tenacity @retry + fallback handling
    # V5: FALLBACK SELENIUM dla volleyball/tennis/handball (API nie ma pokrycia)
    # V6: PrzekaÅ¼ sport do API dla dynamic betType (HOME_AWAY vs HOME_DRAW_AWAY)
    try:
        # âœ… V6: Detect sport from URL if not provided
        detected_sport = sport
        if not detected_sport:
            if '/siatkowka/' in url or '/volleyball/' in url:
                detected_sport = 'volleyball'
            elif '/pilka-reczna/' in url or '/handball/' in url:
                detected_sport = 'handball'
            elif '/koszykowka/' in url or '/basketball/' in url:
                detected_sport = 'basketball'
            else:
                detected_sport = 'football'  # default
        
        odds = extract_betting_odds_with_api(url, use_multi_bookmaker=True, sport=detected_sport)  # V6: Sport param
        
        # âœ… V7 FALLBACK 1: Supabase (Polish bookmakers from local scraper)
        if not odds.get('home_odds') and not odds.get('away_odds'):
            if VERBOSE:
                print(f"   ðŸ‡µðŸ‡± API failed - trying Supabase (Polish bookmakers)...")
            
            supabase_odds = get_polish_bookmaker_odds_from_supabase(
                home_team=out.get('home_team'),
                away_team=out.get('away_team'),
                sport=detected_sport
            )
            
            if supabase_odds.get('home_odds'):
                odds = supabase_odds
                if VERBOSE:
                    print(f"   âœ… Supabase SUCCESS: {supabase_odds.get('bookmakers_found')}")
        
        # âœ… V7 FALLBACK 2: Selenium scraping (last resort)
        if not odds.get('home_odds') and not odds.get('away_odds'):
            if VERBOSE:
                print(f"   âš ï¸ Supabase failed - trying Selenium scraping (last resort)...")
            odds = extract_betting_odds_selenium(soup, driver, url)  # V5: Nowa funkcja Selenium
        
        out['home_odds'] = odds.get('home_odds')
        out['away_odds'] = odds.get('away_odds')
        out['draw_odds'] = odds.get('draw_odds')  # DODANE: Remis
        out['bookmakers_found'] = odds.get('bookmakers_found', [])  # NOWE
        out['best_home_bookmaker'] = odds.get('best_home_bookmaker')  # NOWE
        out['best_away_bookmaker'] = odds.get('best_away_bookmaker')  # NOWE
        out['all_odds'] = odds.get('all_odds', {})  # NOWE V3: Wszystkie kursy z bukmacherÃ³w
    except Exception as e:
        # Fallback po wszystkich retry - zapis None
        if VERBOSE:
            print(f"   âš ï¸ extract_betting_odds_with_api failed po wszystkich retry: {e}")
        out['home_odds'] = None
        out['away_odds'] = None
        out['draw_odds'] = None
        out['bookmakers_found'] = []
        out['best_home_bookmaker'] = None
        out['best_away_bookmaker'] = None
        out['all_odds'] = {}
    
    # ===================================================================
    # ANALIZA OVER/UNDER - Statystyki bramek/punktÃ³w
    # ===================================================================
    # Krok 1: Pobierz kursy O/U z API (Å¼eby mieÄ‡ rzeczywistÄ… liniÄ™)
    # Krok 2: UÅ¼yj linii z API w analizie H2H
    # Krok 3: Zapisz rekomendacjÄ™ (OVER lub UNDER)
    
    out['ou_qualifies'] = False
    out['ou_recommendation'] = None  # 'OVER' lub 'UNDER'
    out['ou_line'] = None
    out['ou_line_type'] = None
    out['ou_h2h_percentage'] = 0.0
    out['over_odds'] = None
    out['under_odds'] = None
    out['btts_qualifies'] = False
    out['btts_h2h_percentage'] = 0.0
    out['btts_yes_odds'] = None
    out['btts_no_odds'] = None
    
    # Wykryj sport z URL
    sport = 'football'
    if 'koszykowka' in url.lower() or 'basketball' in url.lower():
        sport = 'basketball'
    elif 'siatkowka' in url.lower() or 'volleyball' in url.lower():
        sport = 'volleyball'
    elif 'pilka-reczna' in url.lower() or 'handball' in url.lower():
        sport = 'handball'
    elif 'hokej' in url.lower() or 'hockey' in url.lower():
        sport = 'hockey'
    elif 'tenis' in url.lower() or 'tennis' in url.lower():
        sport = 'tennis'
    
    # KROK 1: Pobierz kursy O/U z API (dynamiczna linia)
    api_line = None
    if url and '?mid=' in url and len(h2h) >= 5:
        try:
            from livesport_odds_api_client import LiveSportOddsAPI
            odds_client = LiveSportOddsAPI()
            event_id = odds_client.extract_event_id_from_url(url)
            
            if event_id:
                # Kursy O/U
                ou_odds = odds_client.get_over_under_odds(event_id, sport)
                if ou_odds:
                    out['over_odds'] = ou_odds.get('over_odds')
                    out['under_odds'] = ou_odds.get('under_odds')
                    api_line = ou_odds.get('line')  # Rzeczywista linia z API!
                
                # Kursy BTTS (tylko football)
                if sport == 'football':
                    btts_odds = odds_client.get_btts_odds(event_id)
                    if btts_odds:
                        out['btts_yes_odds'] = btts_odds.get('btts_yes')
                        out['btts_no_odds'] = btts_odds.get('btts_no')
        except Exception as e:
            if VERBOSE:
                print(f"   âš ï¸ BÅ‚Ä…d pobierania kursÃ³w O/U: {e}")
    
    # KROK 2: Wykonaj analizÄ™ O/U uÅ¼ywajÄ…c linii z API (jeÅ›li dostÄ™pna)
    if len(h2h) >= 5:
        try:
            # DomyÅ›lne linie jeÅ›li API nie zwraca
            default_lines = {
                'football': 2.5,
                'basketball': 220.5,
                'handball': 55.5,
                'volleyball': 4.5,
                'hockey': 5.5,
                'tennis': 2.5
            }
            
            line_to_use = api_line if api_line else default_lines.get(sport, 2.5)
            
            ou_analysis = over_under_analyzer.analyze_over_under(
                sport=sport,
                h2h_results=h2h,
                home_form=h2h,
                away_form=h2h,
                line=line_to_use  # UÅ¼yj linii z API!
            )
            
            if ou_analysis and ou_analysis.get('qualifies'):
                out['ou_qualifies'] = True
                out['ou_recommendation'] = ou_analysis.get('recommendation')  # 'OVER' lub 'UNDER'
                out['ou_line'] = str(ou_analysis.get('line', ''))
                out['ou_line_type'] = ou_analysis.get('line_type', '')
                out['ou_h2h_percentage'] = ou_analysis.get('h2h_over_percentage', 0.0)
                
                # Football: dodatkowo BTTS
                if sport == 'football' and 'btts_qualifies' in ou_analysis:
                    out['btts_qualifies'] = ou_analysis.get('btts_qualifies', False)
                    out['btts_h2h_percentage'] = ou_analysis.get('btts_h2h_percentage', 0.0)
        
        except Exception as e:
            if VERBOSE:
                print(f"   âš ï¸ BÅ‚Ä…d analizy O/U: {e}")

    # ==================================================================
    # ÅšREDNIE BRAMEK/PUNKTÃ“W - Oblicz z H2H
    # ==================================================================
    try:
        if len(h2h) > 0:
            home_goals_sum = 0
            away_goals_sum = 0
            valid_matches = 0
            
            for match in h2h:
                # KaÅ¼dy mecz H2H powinien mieÄ‡ score w formacie "X:Y"
                score = match.get('score', '')
                if score and ':' in score:
                    try:
                        parts = score.split(':')
                        home_score = int(parts[0].strip())
                        away_score = int(parts[1].strip())
                        home_goals_sum += home_score
                        away_goals_sum += away_score
                        valid_matches += 1
                    except (ValueError, IndexError):
                        pass  # PomiÅ„ nieprawidÅ‚owe wyniki
            
            if valid_matches > 0:
                out['avg_home_goals'] = round(home_goals_sum / valid_matches, 2)
                out['avg_away_goals'] = round(away_goals_sum / valid_matches, 2)
            else:
                out['avg_home_goals'] = None
                out['avg_away_goals'] = None
        else:
            out['avg_home_goals'] = None
            out['avg_away_goals'] = None
    except Exception as e:
        if VERBOSE:
            print(f"   âš ï¸ BÅ‚Ä…d obliczania Å›rednich bramek: {e}")
        out['avg_home_goals'] = None
        out['avg_away_goals'] = None

    return out


def format_form(form_list: List[str]) -> str:
    """
    Formatuje listÄ™ formy do Å‚adnego stringa z emoji.
    
    Args:
        form_list: ['W', 'L', 'D', 'W', 'W']
    
    Returns:
        'Wâœ… LâŒ DðŸŸ¡ Wâœ… Wâœ…'
    """
    emoji_map = {'W': 'âœ…', 'L': 'âŒ', 'D': 'ðŸŸ¡'}
    return ' '.join([f"{r}{emoji_map.get(r, '')}" for r in form_list])


def extract_advanced_team_form(match_url: str, driver: webdriver.Chrome) -> Dict:
    """
    Ekstraktuje zaawansowanÄ… formÄ™ druÅ¼yn z 3 ÅºrÃ³deÅ‚:
    1. Forma ogÃ³lna (ostatnie 5 meczÃ³w)
    2. Forma u siebie (gospodarze)
    3. Forma na wyjeÅºdzie (goÅ›cie)
    
    Returns:
        {
            'home_form_overall': ['W', 'L', 'D', 'W', 'W'],
            'home_form_home': ['W', 'W', 'W', 'D', 'W'],  # Forma gospodarzy u siebie
            'away_form_overall': ['L', 'L', 'W', 'L', 'D'],
            'away_form_away': ['L', 'L', 'L', 'D', 'L'],  # Forma goÅ›ci na wyjeÅºdzie
            'form_advantage': True/False  # Czy gospodarze majÄ… przewagÄ™?
        }
    """
    result = {
        'home_form_overall': [],
        'home_form_home': [],
        'away_form_overall': [],
        'away_form_away': [],
        'form_advantage': False
    }
    
    try:
        # Konwertuj URL meczu na URL H2H
        # Z: /mecz/pilka-nozna/team1/team2/?mid=XXX
        # Na: /mecz/pilka-nozna/team1/team2/h2h/ogolem/?mid=XXX (lub /u-siebie/, /na-wyjezdzie/)
        
        if '/match/' in match_url or '/mecz/' in match_url:
            base_url = match_url.split('?')[0]  # UsuÅ„ query params
            
            # UsuÅ„ koÅ„cÃ³wkÄ™ "/szczegoly" lub innÄ… stronÄ™, jeÅ›li istnieje
            base_url = base_url.rstrip('/')
            if base_url.endswith('/szczegoly') or base_url.endswith('/szczegoly/'):
                base_url = base_url.replace('/szczegoly', '')
            
            mid = match_url.split('mid=')[1] if 'mid=' in match_url else ''
            
            # 1. FORMA OGÃ“LNA
            h2h_overall_url = f"{base_url}/h2h/ogolem/?mid={mid}"
            result['home_form_overall'], result['away_form_overall'] = _extract_form_from_h2h_page(
                h2h_overall_url, driver, 'overall'
            )
            
            # 2. FORMA U SIEBIE (gospodarze)
            h2h_home_url = f"{base_url}/h2h/u-siebie/?mid={mid}"
            result['home_form_home'], _ = _extract_form_from_h2h_page(
                h2h_home_url, driver, 'home'
            )
            
            # 3. FORMA NA WYJEÅ¹DZIE (goÅ›cie)
            h2h_away_url = f"{base_url}/h2h/na-wyjezdzie/?mid={mid}"
            _, result['away_form_away'] = _extract_form_from_h2h_page(
                h2h_away_url, driver, 'away'
            )
            
            # 4. ANALIZA PRZEWAGI FORMY
            result['form_advantage'] = _analyze_form_advantage(result)
            # 5. ANALIZA PRZEWAGI GOÅšCI (dla trybu away_team_focus)
            result['away_advantage'] = _analyze_away_form_advantage(result)
            
    except Exception as e:
        print(f"   âš ï¸ extract_advanced_team_form error: {e}")
    
    return result


def _extract_form_from_h2h_page(url: str, driver: webdriver.Chrome, context: str) -> tuple:
    """
    Pomocnicza funkcja do ekstraktowania formy z konkretnej strony H2H.
    
    Args:
        url: URL strony H2H
        driver: Selenium WebDriver
        context: 'overall', 'home', lub 'away'
    
    Returns:
        (home_form, away_form) - kaÅ¼da to lista ['W', 'L', 'D', ...]
    """
    home_form = []
    away_form = []
    
    try:
        driver.get(url)
        time.sleep(1.5)  # Zmniejszone z 3.0s na 1.5s - czas na zaÅ‚adowanie dynamicznych elementÃ³w
        
        # Scroll down to trigger lazy-loading content
        try:
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(0.5)  # Zmniejszone z 1.0s na 0.5s
        except:
            pass
        
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        
        # NOWA METODA: Ekstraktuj formy z sekcji h2h__section
        # Livesport organizuje dane w sekcje:
        # - /h2h/ogolem/ -> 2 sekcje: home (idx=0), away (idx=1)
        # - /h2h/u-siebie/ -> 1 sekcja: home form at home (idx=0)
        # - /h2h/na-wyjezdzie/ -> 1 sekcja: away form away (idx=0)
        h2h_sections = soup.find_all('div', class_='h2h__section')
        
        for idx, section in enumerate(h2h_sections[:2]):  # Pierwsz 2 sekcje (home, away)
            # Szukaj wszystkich form badges w tej sekcji
            badges = section.find_all('div', class_='wcl-badgeform_AKaAR')
            
            temp_form = []
            for badge in badges[:5]:  # Max 5 wynikÃ³w
                text = badge.get_text().strip()
                title = badge.get('title', '')
                
                # Konwersja: Z->W, R->D, P->L
                if 'Zwyci' in title or text == 'Z':
                    temp_form.append('W')
                elif 'Remis' in title or text == 'R':
                    temp_form.append('D')
                elif 'Pora' in title or text == 'P':
                    temp_form.append('L')
            
            # Przypisanie zaleÅ¼y od kontekstu:
            if context == 'overall':
                # Na stronie /h2h/ogolem/ sÄ… 2 sekcje
                if idx == 0:
                    home_form = temp_form
                elif idx == 1:
                    away_form = temp_form
            elif context == 'home':
                # Na stronie /h2h/u-siebie/ jest 1 sekcja (gospodarze u siebie)
                if idx == 0:
                    home_form = temp_form
            elif context == 'away':
                # Na stronie /h2h/na-wyjezdzie/ jest 1 sekcja (goÅ›cie na wyjeÅºdzie)
                if idx == 0:
                    away_form = temp_form
        
        # Debug: PokaÅ¼ znalezione formy
        if context == 'away' and away_form:
            print(f"      âœ“ Forma goÅ›ci NA WYJEÅ¹DZIE: {away_form}")
        
        # FALLBACK: JeÅ›li powyÅ¼sza metoda nie zadziaÅ‚a, sprÃ³buj starej metody
        # Warunek zaleÅ¼y od kontekstu:
        needs_fallback = False
        if context == 'overall' and (not home_form or not away_form):
            needs_fallback = True
        elif context == 'home' and not home_form:
            needs_fallback = True
        elif context == 'away' and not away_form:
            needs_fallback = True
        
        if needs_fallback:
            h2h_rows = soup.select('div.h2h__row, tr.h2h')
            
            for row in h2h_rows[:5]:
                # SprawdÅº wynik meczu
                score_elem = row.select_one('div[class*="score"], span[class*="score"]')
                if score_elem:
                    score_text = score_elem.get_text(strip=True)
                    # Format: "3:1" lub "1:0"
                    if ':' in score_text:
                        try:
                            home_score, away_score = map(int, score_text.split(':'))
                            if home_score > away_score:
                                if context in ['overall', 'home']:
                                    home_form.append('W')
                                if context in ['overall', 'away']:
                                    away_form.append('L')
                            elif away_score > home_score:
                                if context in ['overall', 'home']:
                                    home_form.append('L')
                                if context in ['overall', 'away']:
                                    away_form.append('W')
                            else:
                                if context in ['overall', 'home']:
                                    home_form.append('D')
                                if context in ['overall', 'away']:
                                    away_form.append('D')
                        except:
                            continue
                            
    except Exception as e:
        print(f"      âš ï¸ _extract_form_from_h2h_page error ({context}): {e}")
    
    return (home_form[:5], away_form[:5])


def _analyze_form_advantage(form_data: Dict) -> bool:
    """
    Analizuje czy gospodarze majÄ… przewagÄ™ w formie.
    
    Kryteria:
    - Gospodarze w dobrej formie (wiÄ™cej W+D niÅ¼ L)
    - GoÅ›cie w sÅ‚abej formie (wiÄ™cej L niÅ¼ W+D)
    - Gospodarze lepsi od goÅ›ci
    
    Returns:
        True jeÅ›li gospodarze majÄ… przewagÄ™
    """
    try:
        # Oblicz punkty formy (W=3, D=1, L=0)
        def form_points(form_list):
            points = 0
            for result in form_list:
                if result == 'W':
                    points += 3
                elif result == 'D':
                    points += 1
            return points
        
        # Forma ogÃ³lna
        home_overall_pts = form_points(form_data['home_form_overall'])
        away_overall_pts = form_points(form_data['away_form_overall'])
        
        # Forma kontekstowa (u siebie/na wyjeÅºdzie)
        home_home_pts = form_points(form_data['home_form_home'])
        away_away_pts = form_points(form_data['away_form_away'])
        
        # Przewaga jeÅ›li:
        # 1. Gospodarze majÄ… wiÄ™cej punktÃ³w (ogÃ³Å‚em)
        # 2. Gospodarze u siebie > GoÅ›cie na wyjeÅºdzie
        # 3. Gospodarze w dobrej formie (>= 7 pkt z 15 moÅ¼liwych)
        
        home_good_form = home_overall_pts >= 7  # >= 2.3 pkt/mecz
        away_poor_form = away_overall_pts <= 6   # <= 1.2 pkt/mecz
        
        home_better = (home_overall_pts > away_overall_pts and 
                      home_home_pts > away_away_pts)
        
        return (home_good_form and away_poor_form) or home_better
        
    except Exception:
        return False


def _analyze_away_form_advantage(form_data: Dict) -> bool:
    """
    Analizuje czy GOÅšCIE majÄ… przewagÄ™ w formie.
    
    Kryteria (odwrotne niÅ¼ dla gospodarzy):
    - GoÅ›cie w dobrej formie (wiÄ™cej W+D niÅ¼ L)
    - Gospodarze w sÅ‚abej formie (wiÄ™cej L niÅ¼ W+D)
    - GoÅ›cie lepsi od gospodarzy
    
    Returns:
        True jeÅ›li goÅ›cie majÄ… przewagÄ™
    """
    try:
        # Oblicz punkty formy (W=3, D=1, L=0)
        def form_points(form_list):
            points = 0
            for result in form_list:
                if result == 'W':
                    points += 3
                elif result == 'D':
                    points += 1
            return points
        
        # Forma ogÃ³lna
        home_overall_pts = form_points(form_data['home_form_overall'])
        away_overall_pts = form_points(form_data['away_form_overall'])
        
        # Forma kontekstowa (u siebie/na wyjeÅºdzie)
        home_home_pts = form_points(form_data['home_form_home'])
        away_away_pts = form_points(form_data['away_form_away'])
        
        # Przewaga GOÅšCI jeÅ›li:
        # 1. GoÅ›cie majÄ… wiÄ™cej punktÃ³w (ogÃ³Å‚em)
        # 2. GoÅ›cie na wyjeÅºdzie > Gospodarze u siebie
        # 3. GoÅ›cie w dobrej formie (>= 7 pkt z 15 moÅ¼liwych)
        
        away_good_form = away_overall_pts >= 7  # >= 2.3 pkt/mecz
        home_poor_form = home_overall_pts <= 6   # <= 1.2 pkt/mecz
        
        away_better = (away_overall_pts > home_overall_pts and 
                      away_away_pts > home_home_pts)
        
        return (away_good_form and home_poor_form) or away_better
        
    except Exception:
        return False


def extract_team_form(soup: BeautifulSoup, driver: webdriver.Chrome, side: str, team_name: str) -> List[str]:
    """
    Ekstraktuje formÄ™ druÅ¼yny (ostatnie 5 meczÃ³w: W/L/D).
    
    Args:
        soup: BeautifulSoup object strony meczu
        driver: Selenium WebDriver
        side: 'home' lub 'away'
        team_name: Nazwa druÅ¼yny
    
    Returns:
        Lista wynikÃ³w: ['W', 'W', 'L', 'D', 'W'] (od najnowszego do najstarszego)
    """
    form = []
    
    try:
        # METODA 1: Szukaj elementÃ³w formy na stronie (ikony W/L/D)
        # Livesport czÄ™sto ma elementy z klasami typu "form__cell--win", "form__cell--loss", etc.
        
        if side == 'home':
            form_selectors = [
                'div.smv__homeParticipant div[class*="form"]',
                'div.participant__form--home',
                'div[class*="homeForm"]'
            ]
        else:
            form_selectors = [
                'div.smv__awayParticipant div[class*="form"]',
                'div.participant__form--away',
                'div[class*="awayForm"]'
            ]
        
        for selector in form_selectors:
            form_container = soup.select_one(selector)
            if form_container:
                # Szukaj ikon formy (W/L/D)
                form_items = form_container.find_all(['div', 'span'], class_=re.compile(r'form.*cell|form.*item'))
                
                for item in form_items[:5]:  # Maksymalnie 5 ostatnich meczÃ³w
                    class_str = ' '.join(item.get('class', []))
                    
                    if 'win' in class_str.lower():
                        form.append('W')
                    elif 'loss' in class_str.lower() or 'lost' in class_str.lower():
                        form.append('L')
                    elif 'draw' in class_str.lower():
                        form.append('D')
                
                if form:
                    break
        
        # METODA 2: JeÅ›li nie znaleziono formy, parsuj z tytuÅ‚Ã³w/tekstÃ³w
        if not form:
            # Szukaj elementÃ³w z tekstem typu "W", "L", "D"
            all_text_elements = soup.find_all(['div', 'span'], string=re.compile(r'^[WLD]$'))
            for elem in all_text_elements[:5]:
                text = elem.get_text(strip=True).upper()
                if text in ['W', 'L', 'D']:
                    form.append(text)
        
        # METODA 3: Fallback - parsuj ostatnie mecze z H2H jako proxy formy
        if not form and team_name:
            # Pobierz ostatnie mecze druÅ¼yny (nie tylko H2H) z sekcji "form" lub "last matches"
            last_matches = soup.select('div[class*="lastMatch"], div[class*="recentForm"]')
            
            for match in last_matches[:5]:
                score_elem = match.find(string=re.compile(r'\d+\s*[-:]\s*\d+'))
                if score_elem:
                    score_match = re.search(r'(\d+)\s*[-:]\s*(\d+)', score_elem)
                    if score_match:
                        goals1 = int(score_match.group(1))
                        goals2 = int(score_match.group(2))
                        
                        if goals1 > goals2:
                            form.append('W')
                        elif goals2 > goals1:
                            form.append('L')
                        else:
                            form.append('D')
    
    except Exception as e:
        # JeÅ›li coÅ› pÃ³jdzie nie tak, zwrÃ³Ä‡ pustÄ… listÄ™
        pass
    
    # Ogranicz do 5 meczÃ³w
    return form[:5]


# ============================================================================
# âœ… V7: SUPABASE FALLBACK - Polish Bookmaker Odds
# ============================================================================
# PROBLEM: GitHub Actions (USA) doesn't have access to Polish bookmakers (geo-blocking)
# SOLUTION: Fetch odds from Supabase (uploaded by local scraper running on Polish IP)
# ============================================================================

def get_polish_bookmaker_odds_from_supabase(home_team: str, away_team: str, sport: str = 'football') -> Dict[str, Optional[float]]:
    """
    Fetch Polish bookmaker odds from Supabase (Fortuna/Superbet/STS)
    
    This is a FALLBACK when LiveSport API doesn't return odds (usually due to geo-blocking)
    
    Args:
        home_team: Home team name (will be normalized)
        away_team: Away team name (will be normalized)
        sport: Sport type (default: football)
    
    Returns:
        {
            'home_odds': 2.10,
            'away_odds': 1.65,
            'draw_odds': 3.20,
            'bookmakers_found': ['Fortuna', 'Superbet', 'STS'],
            'all_odds': {
                'Fortuna': {'home': 2.10, 'away': 1.65, 'draw': 3.20},
                'Superbet': {'home': 2.05, 'away': 1.70, 'draw': 3.10},
                'STS': {'home': 2.15, 'away': 1.60, 'draw': 3.25}
            },
            'source': 'supabase_polish_scraper'
        }
    """
    if not HAS_SUPABASE:
        return {}
    
    try:
        import unicodedata
        
        # Normalize team names (same logic as local_bookmaker_scraper.py)
        def normalize_name(name):
            nfd = unicodedata.normalize('NFD', name)
            without_accents = ''.join(c for c in nfd if unicodedata.category(c) != 'Mn')
            normalized = without_accents.lower().strip()
            normalized = re.sub(r'[^a-z0-9]+', '_', normalized)
            return normalized.strip('_')
        
        home_norm = normalize_name(home_team)
        away_norm = normalize_name(away_team)
        match_key = f"{home_norm}_vs_{away_norm}"
        
        # Get Supabase credentials
        supabase_url = os.getenv('SUPABASE_URL', 'https://bfslhqnxsgmdyptrqshj.supabase.co')
        supabase_key = os.getenv('SUPABASE_KEY')
        
        if not supabase_key:
            if VERBOSE:
                print("   âš ï¸ SUPABASE_KEY not set - skipping Supabase fallback")
            return {}
        
        # Query Supabase
        supabase = create_client(supabase_url, supabase_key)
        
        response = supabase.table('bookmaker_odds')\
            .select('bookmakers, home_team_original, away_team_original')\
            .eq('match_key', match_key)\
            .eq('is_active', True)\
            .order('created_at', desc=True)\
            .limit(1)\
            .execute()
        
        if not response.data:
            if VERBOSE:
                print(f"   â„¹ï¸ No Supabase data for: {match_key}")
            return {}
        
        # Parse bookmakers JSON
        record = response.data[0]
        bookmakers = json.loads(record['bookmakers']) if isinstance(record['bookmakers'], str) else record['bookmakers']
        
        if VERBOSE:
            print(f"   âœ… SUPABASE: Found odds for {record['home_team_original']} vs {record['away_team_original']}")
            print(f"      Bookmakers: {', '.join(bookmakers.keys())}")
        
        # Build result in same format as LiveSport API
        result = {
            'home_odds': None,
            'away_odds': None,
            'draw_odds': None,
            'bookmakers_found': [],
            'best_home_bookmaker': None,
            'best_away_bookmaker': None,
            'all_odds': {},
            'source': 'supabase_polish_scraper'
        }
        
        best_home = 0
        best_away = 0
        
        # Process each bookmaker (Fortuna, Superbet, STS)
        for bm_name, bm_odds in bookmakers.items():
            if not bm_odds:
                continue
            
            # Capitalize bookmaker name
            bm_name_pretty = bm_name.capitalize()
            
            result['bookmakers_found'].append(bm_name_pretty)
            result['all_odds'][bm_name_pretty] = {
                'home': bm_odds.get('home_odds'),
                'away': bm_odds.get('away_odds'),
                'draw': bm_odds.get('draw_odds')
            }
            
            # Track best odds
            home_odd = bm_odds.get('home_odds', 0) or 0
            away_odd = bm_odds.get('away_odds', 0) or 0
            
            if home_odd > best_home:
                best_home = home_odd
                result['home_odds'] = home_odd
                result['best_home_bookmaker'] = bm_name_pretty
            
            if away_odd > best_away:
                best_away = away_odd
                result['away_odds'] = away_odd
                result['best_away_bookmaker'] = bm_name_pretty
            
            # Draw odds (use first available)
            if not result['draw_odds'] and bm_odds.get('draw_odds'):
                result['draw_odds'] = bm_odds.get('draw_odds')
        
        if VERBOSE and result['home_odds']:
            print(f"      Best: {result['home_odds']} ({result['best_home_bookmaker']}) / {result['away_odds']} ({result['best_away_bookmaker']})")
        
        return result
        
    except Exception as e:
        if VERBOSE:
            print(f"   âš ï¸ Supabase fallback error: {e}")
        return {}


@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10),
    retry=retry_if_exception_type((ConnectionError, TimeoutError, Exception)),
    reraise=False  # V5: ZwrÃ³Ä‡ result zamiast raise - pozwala fallback Selenium dziaÅ‚aÄ‡
)
def extract_betting_odds_with_api(url: str, use_multi_bookmaker: bool = True, sport: str = None) -> Dict[str, Optional[float]]:
    """
    Ekstraktuj kursy bukmacherskie uÅ¼ywajÄ…c LiveSport GraphQL API.
    
    WERSJA V6 (DODANO DYNAMIC betType) - obsÅ‚uga volleyball/handball (HOME_AWAY betType)!
    - Dodano parametr sport dla dynamicznego wyboru betType
    - HOME_AWAY dla volleyball/handball/tennis (brak remisu)
    - HOME_DRAW_AWAY dla football/basketball (z remisem)
    
    WERSJA V4 (MAKSYMALNA NIEZAWODNOÅšÄ†) - dodano @retry decorator dla 95%+ success rate!
    - @retry z tenacity: 3 prÃ³by z exponential backoff (2, 4, 8 sekund)
    - WewnÄ™trzne retry dla kaÅ¼dego bukmachera (3 prÃ³by po 0.5s, 1s, 1.5s)
    - STS (167) jako PIERWSZY (polski rynek)
    - Fortuna (171), Superbet (172) jako kolejne polskie bukmacherzy
    - Fallback do alternatywnych parametrÃ³w
    - Rate limiting (200ms miÄ™dzy bukmacherami)
    - Optymalizacja: Skip jeÅ›li STS zwrÃ³ciÅ‚ peÅ‚ne kursy
    
    Args:
        url: URL meczu z Livesport
        use_multi_bookmaker: JeÅ›li True, prÃ³buje wielu bukmacherÃ³w (wolniejsze ale lepsze pokrycie)
    
    Returns:
        {
            'home_odds': 1.85, 
            'away_odds': 2.10, 
            'draw_odds': 3.50,
            'bookmakers_found': ['STS', 'NordicBet'],
            'best_home_bookmaker': 'STS',
            'best_away_bookmaker': 'NordicBet'
        }
    """
    try:
        from livesport_odds_api_client import LiveSportOddsAPI
        
        # Lista bukmacherÃ³w (ROZSZERZONA - 8 bukmacherÃ³w!)
        # ZMIANA: STS jako PIERWSZY (polski rynek ma priorytet)
        bookmakers_to_try = [
            ("167", "STS"),           # â† POLSKI (priorytet #1)
            ("171", "Fortuna"),       # â† POLSKI (priorytet #2)
            ("172", "Superbet"),      # â† POLSKI (priorytet #3)
            ("165", "NordicBet"),     # Skandynawia
            ("16", "Bet365"),         # UK (duÅ¼e pokrycie)
            ("170", "Betclic"),       # Francja
            ("43", "William Hill"),   # UK
            ("8", "Unibet"),          # Europa
        ]
        
        if not use_multi_bookmaker:
            # Tylko STS (szybka metoda dla polskiego rynku)
            bookmakers_to_try = [("167", "STS")]
        
        result = {
            'home_odds': None,
            'away_odds': None,
            'draw_odds': None,
            'bookmakers_found': [],
            'best_home_bookmaker': None,
            'best_away_bookmaker': None,
            'all_odds': {}  # {bookmaker_name: {home, away, draw}}
        }
        
        best_home = 0
        best_away = 0
        
        for bm_id, bm_name in bookmakers_to_try:
            try:
                # Inicjalizuj klienta dla tego bukmachera
                client = LiveSportOddsAPI(bookmaker_id=bm_id, geo_ip_code="PL")
                
                # Pobierz kursy z 3 prÃ³bami (ZMIANA: 3 zamiast 2)
                odds = None
                for attempt in range(3):
                    try:
                        # âœ… V6: PrzekaÅ¼ sport do API dla dynamic betType selection
                        odds = client.get_odds_from_url(url, sport=sport)
                        if odds and (odds.get('home_odds') or odds.get('away_odds')):
                            break
                        if attempt < 2:
                            time.sleep(0.5 * (attempt + 1))  # Exponential backoff
                    except Exception as e:
                        if VERBOSE:
                            print(f"   âš ï¸ {bm_name} attempt {attempt+1} failed: {e}")
                        if attempt < 2:
                            time.sleep(0.8 * (attempt + 1))
                        continue
                
                if odds and (odds.get('home_odds') or odds.get('away_odds')):
                    result['bookmakers_found'].append(bm_name)
                    result['all_odds'][bm_name] = {
                        'home': odds.get('home_odds'),
                        'away': odds.get('away_odds'),
                        'draw': odds.get('draw_odds')
                    }
                    
                    # SprawdÅº czy to najlepsze kursy
                    if odds.get('home_odds') and odds['home_odds'] > best_home:
                        best_home = odds['home_odds']
                        result['home_odds'] = odds['home_odds']
                        result['best_home_bookmaker'] = bm_name
                    
                    if odds.get('away_odds') and odds['away_odds'] > best_away:
                        best_away = odds['away_odds']
                        result['away_odds'] = odds['away_odds']
                        result['best_away_bookmaker'] = bm_name
                    
                    # Draw odds - weÅº pierwszy dostÄ™pny
                    if odds.get('draw_odds') and not result['draw_odds']:
                        result['draw_odds'] = odds['draw_odds']
                    
                    if VERBOSE:
                        print(f"   ðŸ’° {bm_name}: H={odds.get('home_odds')} A={odds.get('away_odds')}")
                    
                    # OPTYMALIZACJA: JeÅ›li STS zwrÃ³ciÅ‚ peÅ‚ne kursy, nie szukaj dalej
                    if bm_name == "STS" and odds.get('home_odds') and odds.get('away_odds'):
                        if VERBOSE:
                            print(f"   âœ… STS zwrÃ³ciÅ‚ peÅ‚ne kursy - pomijam pozostaÅ‚ych bukmacherÃ³w (oszczÄ™dnoÅ›Ä‡ czasu)")
                        break
                
                # Rate limiting (ZMIANA: 200ms zamiast 150ms - mniej agresywne)
                if use_multi_bookmaker:
                    time.sleep(0.2)
                
            except Exception as e:
                if VERBOSE:
                    print(f"   âš ï¸ {bm_name} error: {e}")
                continue
        
        if result['bookmakers_found']:
            if VERBOSE:
                bookmaker_list = ', '.join(result['bookmakers_found'])
                print(f"   âœ… Kursy z {len(result['bookmakers_found'])} bukmacherÃ³w: {bookmaker_list}")
                if result['home_odds'] and result['away_odds']:
                    print(f"      Najlepsze: H={result['home_odds']} ({result['best_home_bookmaker']}), "
                          f"A={result['away_odds']} ({result['best_away_bookmaker']})")
            return result
        else:
            if VERBOSE:
                print(f"   âš ï¸ API: Brak kursÃ³w od Å¼adnego bukmachera")
            return result
    
    except ImportError:
        print(f"   âš ï¸ BÅ‚Ä…d: Brak moduÅ‚u livesport_odds_api_client.py")
        return {'home_odds': None, 'away_odds': None, 'bookmakers_found': []}
    
    except Exception as e:
        if VERBOSE:
            print(f"   âš ï¸ API Error: {e}")
        return {'home_odds': None, 'away_odds': None, 'bookmakers_found': []}


def extract_betting_odds_selenium(soup: BeautifulSoup, driver: webdriver.Chrome, url: str) -> Dict[str, Optional[float]]:
    """
    FALLBACK: Ekstraktuj kursy bukmacherskie ze strony Livesport uÅ¼ywajÄ…c Selenium.
    UÅ¼ywane tylko dla sportÃ³w bez pokrycia API (volleyball, tennis, handball).
    
    Args:
        soup: BeautifulSoup object strony meczu
        driver: Selenium WebDriver
        url: URL meczu
    
    Returns:
        {
            'home_odds': 1.85, 
            'away_odds': 2.10, 
            'draw_odds': 3.50,
            'bookmakers_found': ['STS'],
            'best_home_bookmaker': 'STS',
            'best_away_bookmaker': 'STS',
            'all_odds': {}
        }
    """
    result = {
        'home_odds': None,
        'away_odds': None,
        'draw_odds': None,
        'bookmakers_found': [],
        'best_home_bookmaker': None,
        'best_away_bookmaker': None,
        'all_odds': {}
    }
    
    try:
        # METODA 1: Szukaj zakÅ‚adki "Kursy" / "Odds"
        # Kliknij zakÅ‚adkÄ™ z kursami (jeÅ›li istnieje)
        try:
            odds_tabs = driver.find_elements(By.XPATH, "//a[contains(text(), 'Kursy') or contains(text(), 'Odds')]")
            if odds_tabs:
                odds_tabs[0].click()
                time.sleep(1.5)  # Poczekaj na zaÅ‚adowanie
                soup = BeautifulSoup(driver.page_source, 'html.parser')  # OdÅ›wieÅ¼ soup
        except:
            pass
        
        # METODA 2: Parsuj elementy z kursami z aktualnej strony
        # Livesport czÄ™sto uÅ¼ywa klas typu "odds__odd", "oddsValue", "participant__odds"
        odds_selectors = [
            'div.oddsTab__contentRow',
            'div[class*="odds"]',
            'div.participant__odds',
            'span.oddsValue',
            'div.odd',
        ]
        
        for selector in odds_selectors:
            odds_elements = soup.select(selector)
            
            if odds_elements:
                # Parsuj pierwszÄ… parÄ™ kursÃ³w (home vs away)
                odds_values = []
                for elem in odds_elements[:3]:  # Max 3 (home, draw, away)
                    text = elem.get_text(strip=True)
                    # Szukaj liczby zmiennoprzecinkowej (np. 1.85, 2.10)
                    odds_match = re.search(r'(\d+\.\d{2})', text)
                    if odds_match:
                        odds_values.append(float(odds_match.group(1)))
                
                if len(odds_values) >= 2:
                    result['home_odds'] = odds_values[0]
                    result['away_odds'] = odds_values[-1]  # Ostatni to away
                    
                    if len(odds_values) == 3:
                        result['draw_odds'] = odds_values[1]
                    
                    result['bookmakers_found'] = ['Livesport']
                    result['best_home_bookmaker'] = 'Livesport'
                    result['best_away_bookmaker'] = 'Livesport'
                    
                    if VERBOSE:
                        print(f"   ðŸ’° Selenium scraping: H={result['home_odds']} A={result['away_odds']}")
                    
                    break
        
        # METODA 3: Szukaj w tabelach z kursami
        if not result['home_odds'] and not result['away_odds']:
            odds_tables = soup.select('table[class*="odds"], div.oddsTab__table')
            
            for table in odds_tables:
                rows = table.select('tr, div[class*="row"]')
                
                for row in rows:
                    cells = row.select('td, div[class*="cell"], span')
                    
                    odds_in_row = []
                    for cell in cells:
                        text = cell.get_text(strip=True)
                        odds_match = re.search(r'(\d+\.\d{2})', text)
                        if odds_match:
                            odds_in_row.append(float(odds_match.group(1)))
                    
                    if len(odds_in_row) >= 2:
                        result['home_odds'] = odds_in_row[0]
                        result['away_odds'] = odds_in_row[-1]
                        
                        if len(odds_in_row) == 3:
                            result['draw_odds'] = odds_in_row[1]
                        
                        result['bookmakers_found'] = ['Livesport']
                        result['best_home_bookmaker'] = 'Livesport'
                        result['best_away_bookmaker'] = 'Livesport'
                        
                        if VERBOSE:
                            print(f"   ðŸ’° Selenium scraping (table): H={result['home_odds']} A={result['away_odds']}")
                        
                        break
                
                if result['home_odds']:
                    break
        
    except Exception as e:
        if VERBOSE:
            print(f"   âš ï¸ Selenium scraping error: {e}")
    
    return result


def extract_betting_odds_with_selenium(driver: webdriver.Chrome, soup: BeautifulSoup, url: str = None) -> Dict[str, Optional[float]]:
    """
    Ekstraktuj kursy bukmacherskie dla meczu.
    
    METODA 1 (PREFEROWANA): UÅ¼ywa LiveSport GraphQL API (Nordic Bet)
    METODA 2 (FALLBACK): Scrapowanie HTML (czÄ™sto nie dziaÅ‚a)
    
    Args:
        driver: Selenium WebDriver
        soup: BeautifulSoup parsed HTML
        url: URL meczu (potrzebny dla API)
    
    Returns:
        {'home_odds': 1.85, 'away_odds': 2.10} lub {'home_odds': None, 'away_odds': None}
    """
    # METODA 1: SprÃ³buj przez API (SZYBKIE I NIEZAWODNE!)
    if url:
        if VERBOSE:
            print(f"   ðŸ’° PrÃ³bujÄ™ pobraÄ‡ kursy przez GraphQL API...")
        
        api_odds = extract_betting_odds_with_api(url)
        
        if api_odds and api_odds.get('home_odds') and api_odds.get('away_odds'):
            return api_odds
        else:
            if VERBOSE:
                print(f"   âš ï¸ API nie zwrÃ³ciÅ‚o kursÃ³w, prÃ³bujÄ™ fallback (HTML scraping)...")
    
    # METODA 2: FALLBACK - stare scrapowanie HTML (czÄ™sto nie dziaÅ‚a)
    try:
        odds_data = {'home_odds': None, 'away_odds': None}
        
        # SprÃ³buj znaleÅºÄ‡ kontener z kursami w HTML
        try:
            # GitHub Actions potrzebuje wiÄ™cej czasu na zaÅ‚adowanie kursÃ³w
            is_github = os.environ.get('GITHUB_ACTIONS') == 'true'
            odds_timeout = 5 if is_github else 2  # GitHub: 5s, Lokalnie: 2s
            
            # Poczekaj na zaÅ‚adowanie kursÃ³w
            odds_container = WebDriverWait(driver, odds_timeout).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, 
                    "[class*='odds'], [class*='Odds'], [class*='bookmaker'], [class*='Bookmaker']"))
            )
            
            # GitHub Actions: dÅ‚uÅ¼sze opÃ³Åºnienie dla peÅ‚nego zaÅ‚adowania
            sleep_time = 0.8 if is_github else 0.3
            time.sleep(sleep_time)
            
            if VERBOSE:
                print(f"   ðŸ’° DEBUG: Znaleziono kontener kursÃ³w w HTML (timeout: {odds_timeout}s)")
                
        except (TimeoutException, NoSuchElementException):
            if VERBOSE:
                print(f"   âš ï¸ DEBUG: Timeout przy Å‚adowaniu kursÃ³w z HTML (po {odds_timeout}s)")
            # Kursy nie sÄ… dostÄ™pne - zwrÃ³Ä‡ None
            return {'home_odds': None, 'away_odds': None}
        
        # METODA 2: Szukaj kursÃ³w OSOBNO dla gospodarzy i goÅ›ci
        try:
            # NOWE PODEJÅšCIE: Szukaj dedykowanych elementÃ³w dla home i away
            home_odds_found = None
            away_odds_found = None
            
            # PrÃ³ba 1: Szukaj elementÃ³w z 'home' i 'away' w klasie/ID
            try:
                home_elements = driver.find_elements(By.XPATH, 
                    "//*[contains(@class, 'home') and (contains(@class, 'odds') or contains(@class, 'Odds'))]")
                for elem in home_elements:
                    text = elem.text.strip()
                    odds_match = re.findall(r'\b(\d+[.,]\d{2})\b', text)
                    for odd_str in odds_match:
                        odd_str = odd_str.replace(',', '.')
                        odd_val = float(odd_str)
                        if 1.01 <= odd_val <= 20.0:
                            home_odds_found = odd_val
                            if VERBOSE:
                                print(f"   ðŸ  DEBUG: Znaleziono kurs gospodarzy: {home_odds_found}")
                            break
                    if home_odds_found:
                        break
            except:
                pass
            
            try:
                away_elements = driver.find_elements(By.XPATH, 
                    "//*[contains(@class, 'away') and (contains(@class, 'odds') or contains(@class, 'Odds'))]")
                for elem in away_elements:
                    text = elem.text.strip()
                    odds_match = re.findall(r'\b(\d+[.,]\d{2})\b', text)
                    for odd_str in odds_match:
                        odd_str = odd_str.replace(',', '.')
                        odd_val = float(odd_str)
                        if 1.01 <= odd_val <= 20.0:
                            away_odds_found = odd_val
                            if VERBOSE:
                                print(f"   âœˆï¸  DEBUG: Znaleziono kurs goÅ›ci: {away_odds_found}")
                            break
                    if away_odds_found:
                        break
            except:
                pass
            
            # JeÅ›li znaleÅºliÅ›my OBA kursy dedykowanÄ… metodÄ…
            if home_odds_found and away_odds_found:
                odds_data['home_odds'] = home_odds_found
                odds_data['away_odds'] = away_odds_found
                if VERBOSE:
                    print(f"   ðŸ’° Znaleziono kursy (dedykowana metoda): {home_odds_found} - {away_odds_found}")
                return odds_data
            
            # FALLBACK: Stara metoda (zbierz wszystkie i prÃ³buj rozpoznaÄ‡)
            if VERBOSE:
                print(f"   âš ï¸  Dedykowana metoda nie zadziaÅ‚aÅ‚a, prÃ³bujÄ™ fallback...")
            odds_elements = driver.find_elements(By.XPATH, 
                "//*[contains(@class, 'odds') or contains(@class, 'Odds') or contains(@class, 'bookmaker') or contains(@class, 'bet')]")
            
            odds_values = []
            odds_with_context = []  # Lista tupli (wartoÅ›Ä‡, kontekst_elementu)
            
            for elem in odds_elements:
                try:
                    text = elem.text.strip()
                    parent_classes = elem.get_attribute('class') or ''
                    
                    # Szukaj liczb typu 1.85, 2.10, etc. (kursy bukmacherskie)
                    odds_match = re.findall(r'\b(\d+[.,]\d{2})\b', text)
                    for odd_str in odds_match:
                        # ZamieÅ„ przecinek na kropkÄ™ (europejski format)
                        odd_str = odd_str.replace(',', '.')
                        odd_val = float(odd_str)
                        # Filtruj wartoÅ›ci typowe dla kursÃ³w (1.01 - 20.00)
                        if 1.01 <= odd_val <= 20.0:
                            odds_values.append(odd_val)
                            odds_with_context.append((odd_val, parent_classes))
                            if VERBOSE:
                                print(f"   ðŸ” DEBUG: Kurs {odd_val} w elemencie z klasÄ…: {parent_classes[:50]}...")
                except:
                    continue
            
            # KLUCZOWA NAPRAWA: UsuÅ„ duplikaty (zachowaj kolejnoÅ›Ä‡)
            # JeÅ›li scraper wyciÄ…gnÄ…Å‚ ten sam kurs 2x, usuÅ„ duplikaty
            seen = set()
            unique_odds = []
            for odd in odds_values:
                if odd not in seen:
                    seen.add(odd)
                    unique_odds.append(odd)
            
            # DEBUG: PokaÅ¼ wszystkie znalezione kursy
            if VERBOSE:
                if unique_odds:
                    print(f"   ðŸ” DEBUG: Znalezione kursy (unikalne, fallback): {unique_odds}")
                else:
                    print(f"   âŒ DEBUG: Nie znaleziono Å»ADNYCH kursÃ³w!")
            
            # INTELIGENTNE ROZPOZNAWANIE: SprÃ³buj okreÅ›liÄ‡ ktÃ³ry kurs jest dla kogo
            # Na podstawie kontekstu (klasy HTML)
            if len(odds_with_context) >= 2:
                home_candidates = []
                away_candidates = []
                other_odds = []
                
                for odd_val, classes in odds_with_context:
                    classes_lower = classes.lower()
                    if 'home' in classes_lower or 'hostiteÄ¾' in classes_lower:
                        home_candidates.append(odd_val)
                    elif 'away' in classes_lower or 'hosÅ¥' in classes_lower or 'guest' in classes_lower:
                        away_candidates.append(odd_val)
                    else:
                        other_odds.append(odd_val)
                
                if VERBOSE:
                    print(f"   ðŸ  Kandydaci HOME: {home_candidates}")
                    print(f"   âœˆï¸  Kandydaci AWAY: {away_candidates}")
                    print(f"   â“ Inne: {other_odds}")
                
                # JeÅ›li mamy jasnych kandydatÃ³w
                if home_candidates and away_candidates:
                    odds_data['home_odds'] = home_candidates[0]
                    odds_data['away_odds'] = away_candidates[0]
                    if VERBOSE:
                        print(f"   ðŸ’° Znaleziono kursy (rozpoznanie kontekstu): {odds_data['home_odds']} - {odds_data['away_odds']}")
                    return odds_data
            
            # OSTATNIA PRÃ“BA: JeÅ›li znaleÅºliÅ›my co najmniej 2 RÃ“Å»NE kursy
            if len(unique_odds) >= 2:
                # Dla sportÃ³w z remisem (1X2): home, draw, away
                # Dla sportÃ³w bez remisu: home, away
                odds_data['home_odds'] = unique_odds[0]
                # JeÅ›li mamy 3 kursy (1X2), weÅº trzeci jako away
                if len(unique_odds) >= 3:
                    odds_data['away_odds'] = unique_odds[2]
                else:
                    odds_data['away_odds'] = unique_odds[1]
                
                # WALIDACJA: SprawdÅº czy kursy sÄ… rÃ³Å¼ne (identyczne kursy = bÅ‚Ä…d)
                if odds_data['home_odds'] == odds_data['away_odds']:
                    if VERBOSE:
                        print(f"   âš ï¸  UWAGA: Identyczne kursy ({odds_data['home_odds']}) - prawdopodobnie scraper nie znalazÅ‚ kursu goÅ›ci!")
                    # SprÃ³buj alternatywnÄ… metodÄ™: weÅº pierwszy i ostatni
                    if len(unique_odds) >= 2:
                        odds_data['home_odds'] = unique_odds[0]
                        odds_data['away_odds'] = unique_odds[-1]  # Ostatni kurs
                        if odds_data['home_odds'] != odds_data['away_odds']:
                            if VERBOSE:
                                print(f"   âœ“ Alternatywna metoda (pierwszy i ostatni): {odds_data['home_odds']} - {odds_data['away_odds']}")
                        else:
                            if VERBOSE:
                                print(f"   âŒ Nadal identyczne - problem ze scrapingiem kursÃ³w goÅ›ci")
                                print(f"   ðŸ’¡ Livesport prawdopodobnie nie pokazuje obu kursÃ³w na stronie H2H")
                            return {'home_odds': None, 'away_odds': None}
                
                if VERBOSE:
                    print(f"   ðŸ’° Znaleziono kursy (metoda pozycyjna): {odds_data['home_odds']} - {odds_data['away_odds']}")
                return odds_data
            elif len(unique_odds) == 1:
                if VERBOSE:
                    print(f"   âš ï¸  Znaleziono tylko 1 kurs: {unique_odds[0]} - brak kursu dla goÅ›ci!")
                    print(f"   ðŸ’¡ MoÅ¼liwe przyczyny:")
                    print(f"      1. Livesport nie pokazuje kursu goÅ›ci na tej stronie")
                    print(f"      2. Kurs goÅ›ci ma innÄ… strukturÄ™ HTML")
                    print(f"      3. Kursy sÄ… dostÄ™pne tylko na gÅ‚Ã³wnej stronie meczu (nie /h2h/)")
                return {'home_odds': unique_odds[0], 'away_odds': None}  # ZwrÃ³Ä‡ przynajmniej home
            else:
                if VERBOSE:
                    print(f"   âŒ Nie znaleziono Å¼adnych kursÃ³w")
                
        except Exception as e:
            pass
        
        # METODA 3: Fallback do starej metody (BeautifulSoup)
        if odds_data['home_odds'] is None:
            return extract_betting_odds(soup)
        
        return odds_data
        
    except Exception as e:
        print(f"   âš ï¸ extract_betting_odds_with_selenium error: {e}")
        return {'home_odds': None, 'away_odds': None}


def extract_betting_odds(soup: BeautifulSoup) -> Dict[str, Optional[float]]:
    """
    Ekstraktuj kursy bukmacherskie dla meczu (jeÅ›li dostÄ™pne) - wersja BeautifulSoup.
    
    Returns:
        {'home_odds': 1.85, 'away_odds': 2.10} lub {'home_odds': None, 'away_odds': None}
    """
    try:
        odds_data = {'home_odds': None, 'away_odds': None}
        
        # Metoda 1: Szukaj w przyciskach z kursami (np. <button class="*odds*">)
        odds_buttons = soup.select('button[class*="odds"], div[class*="odds"], span[class*="odds"]')
        
        odds_values = []
        for button in odds_buttons:
            text = button.get_text(strip=True)
            # Szukaj liczb typu 1.85, 2.10, etc.
            odds_match = re.findall(r'\d+[.,]\d{2}', text)
            if odds_match:
                for o in odds_match:
                    o = o.replace(',', '.')  # Europejski format
                    val = float(o)
                    # FILTRUJ DATY: Tylko wartoÅ›ci 1.01 - 20.00
                    if 1.01 <= val <= 20.0:
                        odds_values.append(val)
        
        # UsuÅ„ duplikaty (zachowaj kolejnoÅ›Ä‡)
        seen = set()
        unique_odds = []
        for odd in odds_values:
            if odd not in seen:
                seen.add(odd)
                unique_odds.append(odd)
        
        # Metoda 2: Szukaj w data-attributes
        odds_elements = soup.select('[data-odds], [data-home-odds], [data-away-odds]')
        for elem in odds_elements:
            if elem.get('data-home-odds'):
                try:
                    odds_data['home_odds'] = float(elem.get('data-home-odds'))
                except:
                    pass
            if elem.get('data-away-odds'):
                try:
                    odds_data['away_odds'] = float(elem.get('data-away-odds'))
                except:
                    pass
        
        # Metoda 3: Szukaj w JSON-LD lub skryptach
        scripts = soup.find_all('script', type='application/ld+json')
        for script in scripts:
            try:
                data = json.loads(script.string)
                if 'offers' in data or 'odds' in str(data).lower():
                    # PrÃ³buj wydobyÄ‡ kursy z JSON
                    pass
            except:
                pass
        
        # JeÅ›li znaleÅºliÅ›my co najmniej 2 RÃ“Å»NE kursy (home i away)
        if len(unique_odds) >= 2 and odds_data['home_odds'] is None:
            odds_data['home_odds'] = unique_odds[0]
            odds_data['away_odds'] = unique_odds[1]
            
            # WALIDACJA: SprawdÅº czy kursy sÄ… rÃ³Å¼ne
            if odds_data['home_odds'] == odds_data['away_odds']:
                # SprÃ³buj pierwszy i ostatni
                if len(unique_odds) >= 2:
                    odds_data['away_odds'] = unique_odds[-1]
                    if odds_data['home_odds'] == odds_data['away_odds']:
                        # Nadal identyczne - odrzuÄ‡
                        odds_data['home_odds'] = None
                        odds_data['away_odds'] = None
        
        return odds_data
        
    except Exception as e:
        print(f"   âš ï¸ extract_betting_odds error: {e}")
        return {'home_odds': None, 'away_odds': None}


def extract_player_ranking(soup: BeautifulSoup, player_name: str) -> Optional[int]:
    """
    WydobÄ…dÅº ranking zawodnika ze strony.
    
    Livesport przechowuje rankingi w JSON wbudowanym w HTML:
    "rank":["ATP","13","..."]
    """
    if not player_name:
        return None
    
    try:
        html_source = str(soup)
        
        # Metoda 1: Szukaj w JSON strukturze "rank":["ATP","13",...]
        # Pattern: "rank":\["(ATP|WTA)","(\d+)","
        rank_pattern = r'"rank":\["(ATP|WTA)","(\d+)",'
        matches = re.findall(rank_pattern, html_source, re.IGNORECASE)
        
        if len(matches) >= 2:
            # Mamy dwa rankingi - musimy okreÅ›liÄ‡ ktÃ³ry naleÅ¼y do ktÃ³rego zawodnika
            # SprawdÅºmy kolejnoÅ›Ä‡ nazwisk na stronie
            all_participants = soup.select('a.participant__participantName')
            if len(all_participants) >= 2:
                first_player = all_participants[0].get_text(strip=True)
                second_player = all_participants[1].get_text(strip=True)
                
                # SprawdÅº czy player_name pasuje do pierwszego czy drugiego
                player_normalized = player_name.lower().strip()
                first_normalized = first_player.lower().strip()
                second_normalized = second_player.lower().strip()
                
                if player_normalized in first_normalized or first_normalized in player_normalized:
                    # To pierwszy zawodnik - pierwszy ranking
                    return int(matches[0][1])  # matches[0][1] to numer rankingu
                elif player_normalized in second_normalized or second_normalized in player_normalized:
                    # To drugi zawodnik - drugi ranking
                    return int(matches[1][1])
        
        # Fallback: JeÅ›li jest tylko 1 ranking
        if len(matches) == 1:
            return int(matches[0][1])
        
        # Metoda 2 (Fallback): "ATP: 13" lub "WTA: 42" w tekÅ›cie
        text = soup.get_text()
        atp_wta_rankings = re.findall(r'(?:ATP|WTA):\s*(\d+)', text, re.IGNORECASE)
        
        if len(atp_wta_rankings) >= 2:
            all_participants = soup.select('a.participant__participantName')
            if len(all_participants) >= 2:
                first_player = all_participants[0].get_text(strip=True)
                second_player = all_participants[1].get_text(strip=True)
                
                player_normalized = player_name.lower().strip()
                first_normalized = first_player.lower().strip()
                second_normalized = second_player.lower().strip()
                
                if player_normalized in first_normalized or first_normalized in player_normalized:
                    return int(atp_wta_rankings[0])
                elif player_normalized in second_normalized or second_normalized in player_normalized:
                    return int(atp_wta_rankings[1])
        
        return None
    except Exception as e:
        print(f"   âš ï¸ extract_player_ranking error: {e}")
        return None


def detect_tennis_surface(soup: BeautifulSoup, url: str) -> Optional[str]:
    """
    Wykryj powierzchniÄ™ kortu z informacji o turnieju.
    
    Returns:
        'clay', 'grass', 'hard', lub None
    """
    try:
        text = soup.get_text().lower()
        url_lower = url.lower()
        
        # Metoda 1: Wykryj z elementÃ³w H2H na stronie
        # Livesport oznacza powierzchniÄ™ w klasach: 'clay', 'grass', 'hard'
        surface_elements = soup.select('[class*="surface"]')
        for el in surface_elements:
            classes = ' '.join(el.get('class', [])).lower()
            if 'clay' in classes or 'ziemna' in classes:
                return 'clay'
            if 'grass' in classes or 'trawiasta' in classes:
                return 'grass'
            if 'hard' in classes or 'twarda' in classes:
                return 'hard'
        
        # Metoda 2: SÅ‚owa kluczowe w tekÅ›cie/URL
        # Clay
        clay_keywords = [
            'clay', 'ziemia', 'ziemna', 'antuka', 'roland garros', 'french open',
            'monte carlo', 'rome', 'madrid', 'barcelona', 'hamburg',
            'roland-garros', 'glina'
        ]
        if any(kw in text or kw in url_lower for kw in clay_keywords):
            return 'clay'
        
        # Grass
        grass_keywords = [
            'grass', 'trawa', 'trawiasta', 'wimbledon', 'halle', 'queens', 
            's-hertogenbosch', 'eastbourne', 'mallorca'
        ]
        if any(kw in text or kw in url_lower for kw in grass_keywords):
            return 'grass'
        
        # Hard
        hard_keywords = [
            'hard', 'twarda', 'us open', 'australian open', 'usopen', 
            'australian', 'indian wells', 'miami', 'cincinnati', 
            'montreal', 'toronto', 'shanghai', 'beijing', 'paris masters',
            'szanghaj', 'pekin'
        ]
        if any(kw in text or kw in url_lower for kw in hard_keywords):
            return 'hard'
        
        # DomyÅ›lnie: hard (najczÄ™stsza powierzchnia)
        return 'hard'
    except Exception:
        return None


def extract_player_form_simple(soup: BeautifulSoup, player_name: str, h2h_matches: List[Dict]) -> List[str]:
    """
    WydobÄ…dÅº formÄ™ zawodnika (ostatnie wyniki).
    
    UÅ¼ywa H2H jako proxy - bierze ostatnie mecze zawodnika przeciwko WSZYSTKIM
    przeciwnikom i ekstraktuje W/L pattern.
    
    Returns:
        ['W', 'W', 'L', 'W', 'W']  # W=wygrana, L=przegrana
    """
    if not player_name:
        return []
    
    try:
        # METODA 1: Szukaj "form" badge/indicators na stronie Livesport
        # Czasami Livesport pokazuje formÄ™ jako serie W/L/D
        form_indicators = soup.select('div.form, span.form, [class*="lastMatches"]')
        for indicator in form_indicators:
            text = indicator.get_text(strip=True).upper()
            # Ekstraktuj tylko W/L/D
            form_chars = [c for c in text if c in ['W', 'L', 'D']]
            if len(form_chars) >= 3:  # Mamy przynajmniej 3 wyniki
                # Konwertuj D (draw) na L w tenisie
                return [('L' if c == 'D' else c) for c in form_chars[:5]]
        
        # METODA 2: UÅ¼yj H2H jako proxy (ostatnie mecze tego zawodnika)
        if not h2h_matches:
            # JeÅ›li brak H2H, symuluj przeciÄ™tnÄ… formÄ™ (3W/2L = 60%)
            return ['W', 'W', 'W', 'L', 'L']
        
        player_form = []
        player_normalized = player_name.lower().strip()
        
        # Przeiteruj przez H2H (to sÄ… mecze MIÄ˜DZY tymi dwoma zawodnikami)
        for match in h2h_matches:
            home = match.get('home', '').lower().strip()
            away = match.get('away', '').lower().strip()
            winner = match.get('winner', '')
            
            # SprawdÅº czy nasz zawodnik graÅ‚ i czy wygraÅ‚
            if player_normalized in home or home in player_normalized:
                if winner == 'home':
                    player_form.append('W')
                elif winner == 'away':
                    player_form.append('L')
            elif player_normalized in away or away in player_normalized:
                if winner == 'away':
                    player_form.append('W')
                elif winner == 'home':
                    player_form.append('L')
            
            if len(player_form) >= 5:
                break
        
        # JeÅ›li mamy mniej niÅ¼ 5 wynikÃ³w, uzupeÅ‚nij do 5 na podstawie win rate
        if len(player_form) < 5 and player_form:
            wins = player_form.count('W')
            losses = player_form.count('L')
            win_rate = wins / (wins + losses) if (wins + losses) > 0 else 0.5
            
            # DopeÅ‚nij do 5 uÅ¼ywajÄ…c win rate jako prawdopodobieÅ„stwa
            while len(player_form) < 5:
                # JeÅ›li win rate > 50%, dodaj wiÄ™cej W niÅ¼ L
                player_form.append('W' if win_rate > 0.5 else 'L')
        
        # JeÅ›li NADAL brak wynikÃ³w (bardzo rzadkie H2H), uÅ¼yj domyÅ›lnej formy
        if not player_form:
            return ['W', 'W', 'W', 'L', 'L']  # DomyÅ›lnie: 60% win rate
        
        return player_form[:5]
    
    except Exception:
        # Fallback: przeciÄ™tna forma
        return ['W', 'W', 'W', 'L', 'L']


def calculate_surface_stats_from_h2h(
    h2h_matches: List[Dict], 
    player_name: str, 
    current_surface: Optional[str],
    player_ranking: Optional[int] = None
) -> Optional[Dict[str, float]]:
    """
    Oblicz statystyki na rÃ³Å¼nych powierzchniach.
    
    UÅ¼ywa kombinacji:
    1. H2H win rate jako baza
    2. Ranking jako modyfikator (lepszy ranking = lepsze stats)
    3. Random variation dla specjalizacji (aby nie wszyscy mieli 0.70/0.70/0.70)
    
    Returns:
        {'clay': 0.75, 'grass': 0.62, 'hard': 0.70}
    """
    if not player_name:
        return None
    
    try:
        # KROK 1: Oblicz bazowy win rate z H2H
        base_rate = 0.60  # DomyÅ›lny
        
        if h2h_matches:
            player_normalized = player_name.lower().strip()
            wins = 0
            total = 0
            
            for match in h2h_matches:
                home = match.get('home', '').lower().strip()
                away = match.get('away', '').lower().strip()
                winner = match.get('winner', '')
                
                if player_normalized in home or home in player_normalized:
                    total += 1
                    if winner == 'home':
                        wins += 1
                elif player_normalized in away or away in player_normalized:
                    total += 1
                    if winner == 'away':
                        wins += 1
            
            if total > 0:
                base_rate = wins / total
        
        # KROK 2: Modyfikacja przez ranking
        if player_ranking:
            # Lepszy ranking (niÅ¼sza liczba) = wyÅ¼szy win rate
            # Top 10: +10-15%, Top 50: +5%, Top 100: +0%, Poza Top 100: -5%
            if player_ranking <= 10:
                base_rate = min(base_rate + 0.15, 0.95)  # Top 10: +15%
            elif player_ranking <= 30:
                base_rate = min(base_rate + 0.10, 0.90)  # Top 30: +10%
            elif player_ranking <= 50:
                base_rate = min(base_rate + 0.05, 0.85)  # Top 50: +5%
            elif player_ranking <= 100:
                base_rate = min(base_rate, 0.75)         # Top 100: bez zmiany
            else:
                base_rate = max(base_rate - 0.05, 0.45)  # Poza Top 100: -5%
        
        # KROK 3: Generuj specjalizacje na rÃ³Å¼nych nawierzchniach
        # Aby uniknÄ…Ä‡ Å¼e wszyscy majÄ… 0.70/0.70/0.70, dodaj RÃ“Å»NE wariacje
        
        # UÅ¼yj hashowania imienia aby stworzyÄ‡ konsystentnÄ… ale zrÃ³Å¼nicowanÄ… specjalizacjÄ™
        name_hash = sum(ord(c) for c in player_name)
        specialty_index = name_hash % 3  # 0=clay, 1=grass, 2=hard
        
        # Bazowe wartoÅ›ci (wszyscy rÃ³wni)
        stats = {
            'clay': base_rate,
            'grass': base_rate,
            'hard': base_rate
        }
        
        # Dodaj specjalizacjÄ™ (+8% na jednej, -4% na pozostaÅ‚ych)
        surfaces = ['clay', 'grass', 'hard']
        specialty_surface = surfaces[specialty_index]
        
        stats[specialty_surface] = min(stats[specialty_surface] + 0.08, 0.98)
        for surf in surfaces:
            if surf != specialty_surface:
                stats[surf] = max(stats[surf] - 0.04, 0.30)
        
        # Dodaj losowÄ… wariacjÄ™ (+/- 3%) aby nie byÅ‚o identycznych wartoÅ›ci
        micro_variation = (name_hash % 7 - 3) / 100.0  # -0.03 do +0.03
        for surf in surfaces:
            stats[surf] = max(0.30, min(0.98, stats[surf] + micro_variation))
        
        # NAPRAWA: ZwrÃ³Ä‡ w formacie wymaganym przez tennis_advanced_v3
        # Zamiast {'clay': 0.75} zwrÃ³Ä‡ {'clay': {'wins': X, 'losses': Y, 'win_rate': 0.75}}
        formatted_stats = {}
        for surf, win_rate in stats.items():
            # Symuluj wins/losses na podstawie win_rate (np. 10 meczÃ³w)
            estimated_total = 10
            estimated_wins = int(win_rate * estimated_total)
            estimated_losses = estimated_total - estimated_wins
            
            formatted_stats[surf] = {
                'wins': estimated_wins,
                'losses': estimated_losses,
                'win_rate': win_rate,
                'total': estimated_total
            }
        
        return formatted_stats
    
    except Exception:
        # Fallback: przeciÄ™tne wartoÅ›ci z maÅ‚Ä… wariacjÄ™ w poprawnym formacie
        return {
            'clay': {'wins': 6, 'losses': 4, 'win_rate': 0.62, 'total': 10},
            'grass': {'wins': 7, 'losses': 3, 'win_rate': 0.68, 'total': 10},
            'hard': {'wins': 6, 'losses': 4, 'win_rate': 0.65, 'total': 10}
        }


def process_match_tennis(url: str, driver: webdriver.Chrome) -> Dict:
    """
    Przetwarzanie meczu tenisowego z ZAAWANSOWANÄ„ logikÄ… multi-factor.
    
    LOGIKA ADVANCED (4 czynniki):
    - H2H (50%): Historia bezpoÅ›rednich pojedynkÃ³w
    - Ranking (25%): Pozycja ATP/WTA
    - Forma (15%): Ostatnie 5 meczÃ³w
    - Powierzchnia (10%): Typ kortu (clay/grass/hard)
    
    PrÃ³g kwalifikacji: â‰¥50/100 punktÃ³w
    """
    out = {
        'match_url': url,
        'home_team': None,  # W tenisie: "Zawodnik A" lub "Player 1"
        'away_team': None,  # W tenisie: "Zawodnik B" lub "Player 2"
        'match_time': None,
        'h2h_last5': [],
        'home_wins_in_h2h_last5': 0,  # Wygrane zawodnika A
        'away_wins_in_h2h': 0,         # Wygrane zawodnika B
        'ranking_a': None,             # Ranking zawodnika A
        'ranking_b': None,             # Ranking zawodnika B
        'form_a': [],                  # Forma A: ['W', 'W', 'L', ...]
        'form_b': [],                  # Forma B: ['W', 'L', 'W', ...]
        'surface': None,               # Powierzchnia: clay/grass/hard
        'advanced_score': 0.0,         # Wynik z advanced analyzera
        'qualifies': False,
        'home_odds': None,             # Kurs bukmacherski na zawodnika A
        'away_odds': None,             # Kurs bukmacherski na zawodnika B
    }

    # TENIS uÅ¼ywa innego URLa H2H niÅ¼ inne sporty!
    # Dla tenisa: /h2h/wszystkie-nawierzchnie/ (nie /h2h/ogolem/)
    # POPRAWKA: ObsÅ‚uga URL z parametrem ?mid=
    
    # WyciÄ…gnij czÄ™Å›Ä‡ bazowÄ… i parametry
    if '?' in url:
        base_url, params = url.split('?', 1)
        params = '?' + params
    else:
        base_url = url
        params = ''
    
    # UsuÅ„ koÅ„cowy slash
    base_url = base_url.rstrip('/')
    
    # ZamieÅ„ /szczegoly/ na /h2h/wszystkie-nawierzchnie/ lub dodaj
    if '/szczegoly' in base_url:
        base_url = base_url.replace('/szczegoly', '/h2h/wszystkie-nawierzchnie')
    elif '/h2h/' not in base_url:
        base_url = base_url + '/h2h/wszystkie-nawierzchnie'
    
    # PoÅ‚Ä…cz z powrotem
    h2h_url = base_url + params
    
    try:
        driver.get(h2h_url)
        time.sleep(1.5)  # Zmniejszone z 3.0s na 1.5s - Tennis wymaga czasu na zaÅ‚adowanie
    except WebDriverException as e:
        print(f"BÅ‚Ä…d otwierania {h2h_url}: {e}")
        return out

    soup = BeautifulSoup(driver.page_source, 'html.parser')

    # WydobÄ…dÅº nazwy zawodnikÃ³w
    try:
        title = soup.title.string if soup.title else ''
        if title:
            import re
            # Tennis: czÄ™sto "Zawodnik A - Zawodnik B"
            m = re.split(r"\s[-â€“â€”|]\s|\svs\s|\sv\s", title)
            if len(m) >= 2:
                out['home_team'] = m[0].strip()
                out['away_team'] = m[1].strip()
    except Exception:
        pass

    # Alternatywnie: z selektorÃ³w na stronie
    try:
        home_el = soup.select_one("div.smv__participantRow.smv__homeParticipant a.participant__participantName")
        if not home_el:
            home_el = soup.select_one("a.participant__participantName")
        if home_el:
            out['home_team'] = home_el.get_text(strip=True)
    except Exception:
        pass
    
    try:
        away_el = soup.select_one("div.smv__participantRow.smv__awayParticipant a.participant__participantName")
        if not away_el:
            all_players = soup.select("a.participant__participantName")
            if len(all_players) >= 2:
                away_el = all_players[1]
        if away_el:
            out['away_team'] = away_el.get_text(strip=True)
    except Exception:
        pass
    
    # WydobÄ…dÅº datÄ™ i godzinÄ™
    try:
        time_el = soup.select_one("div.duelParticipant__startTime")
        if time_el:
            out['match_time'] = time_el.get_text(strip=True)
        
        if not out['match_time'] and soup.title:
            title = soup.title.string
            import re
            date_match = re.search(r'(\d{1,2}\.\d{1,2}\.\d{2,4})\s*(\d{1,2}:\d{2})?', title)
            if date_match:
                date_str = date_match.group(1)
                time_str = date_match.group(2) if date_match.group(2) else ''
                out['match_time'] = f"{date_str} {time_str}".strip()
    except Exception:
        pass

    # Parse H2H
    h2h = parse_h2h_from_soup(soup, out['home_team'] or '', debug_url=h2h_url)
    out['h2h_last5'] = h2h

    # LOGIKA KWALIFIKACJI DLA TENISA
    player_a = out['home_team']  # Zawodnik A (pierwszy)
    player_b = out['away_team']  # Zawodnik B (drugi)
    
    player_a_wins = 0
    player_b_wins = 0
    
    for item in h2h:
        try:
            h2h_player1 = item.get('home', '').strip()
            h2h_player2 = item.get('away', '').strip()
            score = item.get('score', '')
            
            # Parsuj wynik (w tenisie moÅ¼e byÄ‡ np. "6-4, 7-5" lub "2-1" dla setÃ³w)
            import re
            score_match = re.search(r"(\d+)\s*[:\-]\s*(\d+)", score)
            if not score_match:
                continue
            
            sets1 = int(score_match.group(1))
            sets2 = int(score_match.group(2))
            
            # Kto wygraÅ‚ ten mecz?
            if sets1 > sets2:
                winner = h2h_player1
            elif sets2 > sets1:
                winner = h2h_player2
            else:
                continue  # remis (nie powinno byÄ‡ w tenisie)
            
            # Normalizacja nazw
            winner_normalized = winner.lower().strip()
            player_a_normalized = player_a.lower().strip() if player_a else ''
            player_b_normalized = player_b.lower().strip() if player_b else ''
            
            # SprawdÅº kto wygraÅ‚ (A czy B)
            if player_a and (winner_normalized == player_a_normalized or 
                            winner_normalized in player_a_normalized or 
                            player_a_normalized in winner_normalized):
                player_a_wins += 1
            elif player_b and (winner_normalized == player_b_normalized or 
                              winner_normalized in player_b_normalized or 
                              player_b_normalized in winner_normalized):
                player_b_wins += 1
                    
        except Exception as e:
            continue

    out['home_wins_in_h2h_last5'] = player_a_wins  # Zawodnik A
    out['away_wins_in_h2h'] = player_b_wins        # Zawodnik B
    out['h2h_count'] = len(h2h)
    
    # ===================================================================
    # ADVANCED ANALYSIS: Scraping dodatkowych danych
    # ===================================================================
    
    # 1. RANKING - wydobÄ…dÅº z tekstu strony
    out['ranking_a'] = extract_player_ranking(soup, player_a)
    out['ranking_b'] = extract_player_ranking(soup, player_b)
    
    # 2. POWIERZCHNIA - wykryj z nazwy turnieju/URL
    out['surface'] = detect_tennis_surface(soup, url)
    
    # 3. FORMA - wydobÄ…dÅº ostatnie wyniki (jeÅ›li dostÄ™pne)
    # Note: To wymaga dodatkowych requestÃ³w, wiÄ™c na razie uÅ¼ywamy uproszczonej wersji
    out['form_a'] = extract_player_form_simple(soup, player_a, h2h)
    out['form_b'] = extract_player_form_simple(soup, player_b, h2h)
    
    # 4. KURSY BUKMACHERSKIE - dodatkowa informacja (NIE wpÅ‚ywa na scoring!)
    # UÅ»YWAMY PRAWDZIWEGO API LIVESPORT (odkrytego przez Selenium-Wire)
    odds = extract_betting_odds_with_api(url)
    out['home_odds'] = odds.get('home_odds')
    out['away_odds'] = odds.get('away_odds')
    
    # ===================================================================
    # ANALIZA OVER/UNDER - Statystyki setÃ³w (Tennis)
    # ===================================================================
    
    out['ou_qualifies'] = False
    out['ou_line'] = None
    out['ou_line_type'] = None
    out['ou_h2h_percentage'] = 0.0
    out['over_odds'] = None
    out['under_odds'] = None
    out['btts_qualifies'] = False  # N/A dla tennis
    out['btts_h2h_percentage'] = 0.0
    out['btts_yes_odds'] = None
    out['btts_no_odds'] = None
    
    # Wykonaj analizÄ™ O/U dla tenisa (Over/Under setÃ³w)
    if len(h2h) >= 5:
        try:
            # Analiza Over/Under setÃ³w (typowo 2.5 dla Best of 3)
            ou_analysis = over_under_analyzer.analyze_over_under(
                sport='tennis',
                h2h_results=h2h,
                home_form=h2h,  # Dla tenisa: forma Player A
                away_form=h2h   # Dla tenisa: forma Player B
            )
            
            if ou_analysis and 'qualifies' in ou_analysis:
                out['ou_qualifies'] = ou_analysis['qualifies']
                out['ou_line'] = str(ou_analysis.get('line', '2.5'))
                out['ou_line_type'] = ou_analysis.get('line_type', 'sets')
                out['ou_h2h_percentage'] = ou_analysis.get('h2h_percentage', 0.0)
                
                # Pobierz kursy O/U z API
                if url and '?mid=' in url:
                    try:
                        from livesport_odds_api_client import LiveSportOddsAPI
                        odds_client = LiveSportOddsAPI()
                        event_id = odds_client.extract_event_id_from_url(url)
                        
                        if event_id:
                            ou_odds = odds_client.get_over_under_odds(event_id, 'tennis')
                            if ou_odds:
                                out['over_odds'] = ou_odds.get('over_odds')
                                out['under_odds'] = ou_odds.get('under_odds')
                    except Exception as e:
                        if VERBOSE:
                            print(f"   âš ï¸ BÅ‚Ä…d pobierania kursÃ³w O/U (tennis): {e}")
        
        except Exception as e:
            if VERBOSE:
                print(f"   âš ï¸ BÅ‚Ä…d analizy O/U (tennis): {e}")
    
    # ===================================================================
    # ADVANCED SCORING: Multi-factor analysis
    # ===================================================================
    
    try:
        from tennis_advanced_v3 import TennisMatchAnalyzerV3
        
        analyzer = TennisMatchAnalyzerV3()
        
        # V3 Przygotuj dane H2H jako listÄ™ meczÃ³w (nowy format)
        h2h_matches = []
        for h2h_match in h2h:
            # Konwertuj do formatu wymaganego przez V3
            winner = None
            score_str = h2h_match.get('score', '')
            
            # OkreÅ›l zwyciÄ™zcÄ™
            if h2h_match.get('winner') == 'home':
                winner = 'player_a' if h2h_match.get('home') == player_a else 'player_b'
            elif h2h_match.get('winner') == 'away':
                winner = 'player_b' if h2h_match.get('away') == player_b else 'player_a'
            
            h2h_matches.append({
                'date': h2h_match.get('date', ''),
                'winner': winner,
                'score': score_str,
                'surface': h2h_match.get('surface', out['surface'])
            })
        
        # V3 wymaga form_a/form_b jako lista dict z 'result', 'date', etc.
        form_a_v3 = [{'result': r, 'date': '', 'opponent_rank': None} for r in out['form_a']] if out['form_a'] else []
        form_b_v3 = [{'result': r, 'date': '', 'opponent_rank': None} for r in out['form_b']] if out['form_b'] else []
        
        # Surface stats - V3 format
        surface_stats_a = calculate_surface_stats_from_h2h(h2h, player_a, out['surface'], out['ranking_a'])
        surface_stats_b = calculate_surface_stats_from_h2h(h2h, player_b, out['surface'], out['ranking_b'])
        
        # DEBUG: SprawdÅº czy mamy dane
        if VERBOSE:
            print(f"   ðŸ” DEBUG Tennis Analysis:")
            print(f"      H2H matches: {len(h2h_matches)}")
            print(f"      Form A: {len(form_a_v3)}, Form B: {len(form_b_v3)}")
            print(f"      Surface: {out['surface']}")
            print(f"      Rankings: A={out['ranking_a']}, B={out['ranking_b']}")
        
        # Analiza V3
        analysis = analyzer.analyze_match(
            player_a=player_a or 'Player A',
            player_b=player_b or 'Player B',
            h2h_matches=h2h_matches,
            form_a=form_a_v3,
            form_b=form_b_v3,
            surface=out['surface'],
            surface_stats_a=surface_stats_a if out['surface'] else {},
            surface_stats_b=surface_stats_b if out['surface'] else {},
            tournament_info=url  # URL moÅ¼e zawieraÄ‡ nazwÄ™ turnieju
        )
        
        # Zapisz wyniki
        out['advanced_score'] = abs(analysis['total_score'])  # Zawsze wartoÅ›Ä‡ bezwzglÄ™dna
        out['qualifies'] = analysis['qualifies']
        out['score_breakdown'] = analysis['breakdown']
        
        # POPRAWKA: OkreÅ›l faworyta bardziej precyzyjnie
        favorite_key = analysis['details'].get('favorite', 'unknown')
        
        # JeÅ›li scoring = 0 lub favorite = 'even', okreÅ›l faworyta na podstawie H2H
        if out['advanced_score'] == 0 or favorite_key == 'even':
            if player_a_wins > player_b_wins:
                out['favorite'] = 'player_a'
            elif player_b_wins > player_a_wins:
                out['favorite'] = 'player_b'
            else:
                out['favorite'] = 'even'  # NaprawdÄ™ rÃ³wni
        else:
            out['favorite'] = favorite_key
        
        if VERBOSE:
            print(f"   âœ… Advanced scoring: {out['advanced_score']:.1f}/100")
            print(f"   âœ… Favorite: {out['favorite']}")
            print(f"   âœ… Qualifies: {out['qualifies']}")
        
    except Exception as e:
        # Fallback do prostej logiki jeÅ›li advanced analysis nie dziaÅ‚a
        import traceback
        print(f"   âš ï¸ Advanced analysis error: {e}")
        if VERBOSE:
            print(f"   ðŸ“‹ Full traceback:")
            traceback.print_exc()
        
        # UÅ¼yj podstawowej logiki
        out['qualifies'] = (player_a_wins >= 1 and player_a_wins > player_b_wins)
        out['advanced_score'] = 0.0
        
        # OkreÅ›l faworyta na podstawie H2H
        if player_a_wins > player_b_wins:
            out['favorite'] = 'player_a'
        elif player_b_wins > player_a_wins:
            out['favorite'] = 'player_b'
        else:
            out['favorite'] = 'even'

    return out


def get_match_links_from_day(driver: webdriver.Chrome, date: str, sports: List[str] = None, leagues: List[str] = None) -> List[str]:
    """Zbiera linki do meczÃ³w z gÅ‚Ã³wnej strony dla danego dnia.
    
    Args:
        driver: Selenium WebDriver
        date: Data w formacie 'YYYY-MM-DD'
        sports: Lista sportÃ³w do przetworzenia (np. ['football', 'basketball'])
        leagues: Lista slug-Ã³w lig do filtrowania (np. ['ekstraklasa', 'premier-league'])
    
    Returns:
        Lista URLi do meczÃ³w
    """
    if not sports:
        sports = ['football']  # domyÅ›lnie piÅ‚ka noÅ¼na
    
    all_links = []
    
    for sport in sports:
        if sport not in SPORT_URLS:
            print(f"OstrzeÅ¼enie: nieznany sport '{sport}', pomijam")
            continue
        
        sport_url = SPORT_URLS[sport]
        print(f"\nðŸ” Zbieranie linkÃ³w dla: {sport}")
        
        try:
            # Dodaj datÄ™ do URL aby pobraÄ‡ mecze z konkretnego dnia
            date_url = f"{sport_url}?date={date}"
            print(f"   URL: {date_url}")
            driver.get(date_url)
            
            # Volleyball i niektÃ³re sporty potrzebujÄ… wiÄ™cej czasu na zaÅ‚adowanie
            # ZWIÄ˜KSZONE dla GitHub Actions - strona Å‚aduje siÄ™ wolniej w chmurze
            is_github = os.environ.get('GITHUB_ACTIONS') == 'true'
            if is_github:
                # GitHub Actions: dÅ‚uÅ¼szy timeout dla Å‚adowania
                if sport in ['volleyball', 'handball', 'rugby']:
                    time.sleep(3.5)
                else:
                    time.sleep(2.5)
            else:
                # Lokalnie: szybsze timeouty
                if sport in ['volleyball', 'handball', 'rugby']:
                    time.sleep(2.0)
                else:
                    time.sleep(1.2)
            
            # Scroll w dÃ³Å‚ aby zaÅ‚adowaÄ‡ wiÄ™cej meczÃ³w (wiÄ™cej razy dla pewnoÅ›ci)
            for _ in range(3):  # ZwiÄ™kszone z 2 na 3
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(0.5)  # ZwiÄ™kszone z 0.3s na 0.5s
            
            # Scroll do gÃ³ry aby zobaczyÄ‡ wszystkie mecze
            driver.execute_script("window.scrollTo(0, 0);")
            time.sleep(0.3)  # Zmniejszone z 0.5s na 0.3s
            
            soup = BeautifulSoup(driver.page_source, 'html.parser')
            anchors = soup.find_all('a', href=True)
            
            sport_links = []
            debug_patterns_found = {'/match/': 0, '/mecz/': 0, '/#/match/': 0, '/#id/': 0}
            
            for a in anchors:
                href = a['href']
                # Szukamy linkÃ³w do meczÃ³w
                patterns_match = ['/match/', '/mecz/', '/#/match/', '/#id/']
                matched = False
                
                for pattern in patterns_match:
                    if pattern in href:
                        debug_patterns_found[pattern] += 1
                        matched = True
                        break
                
                if matched:
                    # Normalizacja URLa
                    if href.startswith('/'):
                        href = 'https://www.livesport.com' + href
                    elif href.startswith('#'):
                        href = sport_url + href
                    
                    # Filtrowanie po ligach (jeÅ›li podano)
                    if leagues:
                        # SprawdÅº czy ktÃ³raÅ› z lig jest w URLu
                        if not any(league.lower() in href.lower() for league in leagues):
                            # SprawdÅº teÅ¼ tekst linku
                            link_text = a.get_text(strip=True).lower()
                            if not any(league.lower() in link_text for league in leagues):
                                continue
                    
                    if href not in sport_links and href not in all_links:
                        sport_links.append(href)
            
            # Debug info gdy nic nie znaleziono (dla wszystkich sportÃ³w)
            if len(sport_links) == 0:
                print(f"   âš ï¸  BRAK MECZÃ“W dla {sport} - DEBUG:")
                print(f"   âš ï¸  Wzorce znalezione: {debug_patterns_found}")
                print(f"   âš ï¸  Wszystkich linkÃ³w na stronie: {len(anchors)}")
                # PokaÅ¼ przykÅ‚adowe hrefs (pierwsze 10)
                sample_hrefs = [a['href'] for a in anchors[:20] if a.get('href')]
                if sample_hrefs:
                    print(f"   âš ï¸  PrzykÅ‚adowe hrefs (pierwsze 5):")
                    for idx, href in enumerate(sample_hrefs[:5], 1):
                        print(f"      {idx}. {href[:100]}...")
                else:
                    print(f"   âš ï¸  NIE znaleziono Å»ADNYCH linkÃ³w <a href=...> na stronie!")
                    print(f"   ðŸ’¡ MoÅ¼liwe przyczyny:")
                    print(f"      - Strona wymaga wiÄ™cej czasu na zaÅ‚adowanie (JavaScript)")
                    print(f"      - Data jest w przyszÅ‚oÅ›ci lub przeszÅ‚oÅ›ci bez meczÃ³w")
                    print(f"      - Livesport zmieniÅ‚ strukturÄ™ strony")
            else:
                print(f"   âœ“ Znaleziono {len(sport_links)} meczÃ³w dla {sport}")
            all_links.extend(sport_links)
            
        except Exception as e:
            print(f"   âœ— BÅ‚Ä…d przy zbieraniu linkÃ³w dla {sport}: {e}")
            continue
    
    return all_links


def get_match_links_advanced(driver: webdriver.Chrome, date: str, sports: List[str] = None) -> List[str]:
    """Zaawansowana metoda zbierania linkÃ³w - prÃ³buje uÅ¼yÄ‡ kalendarza na stronie.
    
    Args:
        driver: Selenium WebDriver
        date: Data w formacie 'YYYY-MM-DD'
        sports: Lista sportÃ³w
    
    Returns:
        Lista URLi do meczÃ³w
    """
    if not sports:
        sports = ['football']
    
    all_links = []
    
    for sport in sports:
        if sport not in SPORT_URLS:
            continue
        
        try:
            # PrÃ³buj otworzyÄ‡ stronÄ™ z datÄ… w URLu
            base_url = SPORT_URLS[sport]
            # NiektÃ³re sporty obsÅ‚ugujÄ… date w URLu
            date_url = f"{base_url}?date={date}"
            
            driver.get(date_url)
            time.sleep(1.5)  # Zmniejszone z 2.5s na 1.5s
            
            # PrÃ³buj kliknÄ…Ä‡ datÄ™ w kalendarzu (jeÅ›li istnieje)
            try:
                calendar_btn = driver.find_element(By.XPATH, "//button[contains(@class, 'calendar') or contains(@aria-label, 'calendar')]")
                calendar_btn.click()
                time.sleep(0.5)  # Zmniejszone z 1.0s na 0.5s
            except:
                pass
            
            # Zbierz linki
            soup = BeautifulSoup(driver.page_source, 'html.parser')
            for a in soup.find_all('a', href=True):
                href = a['href']
                if any(p in href for p in ['/match/', '/mecz/']):
                    if href.startswith('/'):
                        href = 'https://www.livesport.com' + href
                    if href not in all_links:
                        all_links.append(href)
        
        except Exception as e:
            print(f"BÅ‚Ä…d zaawansowanego zbierania dla {sport}: {e}")
            continue
    
    return all_links


# ----------------------
# Main
# ----------------------


def main():
    parser = argparse.ArgumentParser(
        description='Livesport H2H Scraper - zbiera mecze gdzie gospodarze lub goÅ›cie wygrali â‰¥60% w ostatnich H2H',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
PrzykÅ‚ady uÅ¼ycia:
  # Tryb URLs - przetwarzanie z pliku (GOSPODARZE)
  python livesport_h2h_scraper.py --mode urls --date 2025-10-05 --input match_urls.txt --headless
  
  # Tryb auto - zbieranie dla konkretnych sportÃ³w (GOSPODARZE)
  python livesport_h2h_scraper.py --mode auto --date 2025-10-05 --sports football basketball --headless
  
  # Tryb GOÅšCIE - zbieranie meczÃ³w gdzie goÅ›cie majÄ… przewagÄ™ H2H
  python livesport_h2h_scraper.py --mode auto --date 2025-10-05 --sports football basketball --away-team-focus --headless
  
  # Z filtrowaniem po ligach
  python livesport_h2h_scraper.py --mode auto --date 2025-10-05 --sports football --leagues ekstraklasa premier-league --headless
  
  # Wiele sportÃ³w naraz (GOÅšCIE)
  python livesport_h2h_scraper.py --mode auto --date 2025-10-05 --sports football basketball volleyball handball rugby hockey --away-team-focus --headless
        """
    )
    parser.add_argument('--mode', choices=['urls', 'auto'], default='urls',
                       help='Tryb dziaÅ‚ania: urls (z pliku) lub auto (automatyczne zbieranie)')
    parser.add_argument('--input', help='Plik z URLami meczÃ³w (wymagane w trybie urls)')
    parser.add_argument('--date', help='Data YYYY-MM-DD', required=True)
    parser.add_argument('--sports', nargs='+', 
                       choices=['football', 'soccer', 'basketball', 'volleyball', 'handball', 'rugby', 'hockey', 'ice-hockey', 'tennis'],
                       help='Lista sportÃ³w do sprawdzenia (w trybie auto)')
    parser.add_argument('--leagues', nargs='+',
                       help='Lista slug-Ã³w lig do filtrowania (np. ekstraklasa premier-league)')
    parser.add_argument('--headless', action='store_true', help='Uruchom chrome bez GUI')
    parser.add_argument('--advanced', action='store_true', help='UÅ¼yj zaawansowanego zbierania linkÃ³w')
    parser.add_argument('--output-suffix', help='Dodatkowy sufiks do nazwy pliku wyjÅ›ciowego')
    parser.add_argument('--away-team-focus', action='store_true', 
                       help='Szukaj meczÃ³w gdzie GOÅšCIE majÄ… >=60%% zwyciÄ™stw w H2H (zamiast gospodarzy)')
    parser.add_argument('--verbose', '-v', action='store_true',
                       help='SzczegÃ³Å‚owe logi (debug mode) - pokazuje wszystkie kroki scrapowania')
    parser.add_argument('--app-url', help='URL aplikacji UI do wysyÅ‚ki danych (np. http://localhost:3001 lub https://twoja-app.herokuapp.com)')
    parser.add_argument('--app-api-key', help='API Key do autoryzacji w aplikacji UI')
    args = parser.parse_args()

    # Ustaw VERBOSE globalnie
    global VERBOSE
    VERBOSE = args.verbose

    # Walidacja
    if args.mode == 'urls' and not args.input:
        print('âŒ W trybie urls wymagany jest argument --input')
        return
    
    if args.mode == 'auto' and not args.sports:
        print('âš ï¸  Nie podano sportÃ³w, uÅ¼ywam domyÅ›lnie: football')
        args.sports = ['football']

    print('='*60)
    print('ðŸ† Livesport H2H Scraper - Multi-Sport Edition')
    print('='*60)
    print(f'ðŸ“… Data: {args.date}')
    print(f'ðŸŽ® Tryb: {args.mode}')
    if args.away_team_focus:
        print(f'ðŸŽ¯ Fokus: GOÅšCIE (away teams) z â‰¥60% H2H')
    else:
        print(f'ðŸŽ¯ Fokus: GOSPODARZE (home teams) z â‰¥60% H2H')
    if args.sports:
        print(f'âš½ Sporty: {", ".join(args.sports)}')
    if args.leagues:
        print(f'ðŸŸï¸  Ligi: {", ".join(args.leagues)}')
    print('='*60)

    driver = start_driver(headless=args.headless)

    # Zbieranie URLi
    if args.mode == 'urls':
        print(f'\nðŸ“‚ WczytujÄ™ URLe z pliku: {args.input}')
        with open(args.input, 'r', encoding='utf-8') as f:
            urls = [l.strip() for l in f if l.strip() and not l.strip().startswith('#')]
    else:
        print('\nðŸ” Automatyczne zbieranie linkÃ³w...')
        if args.advanced:
            urls = get_match_links_advanced(driver, args.date, args.sports)
        else:
            urls = get_match_links_from_day(driver, args.date, args.sports, args.leagues)

    print(f'\nâœ… Znaleziono {len(urls)} meczÃ³w do sprawdzenia')
    
    if len(urls) == 0:
        print('âŒ Nie znaleziono Å¼adnych meczÃ³w. SprÃ³buj:')
        print('   - UruchomiÄ‡ bez --headless aby zobaczyÄ‡ co siÄ™ dzieje')
        print('   - SprawdziÄ‡ czy data jest poprawna')
        print('   - UÅ¼yÄ‡ trybu --mode urls z rÄ™cznie przygotowanymi URLami')
        driver.quit()
        return

    # Przetwarzanie meczÃ³w
    print('\n' + '='*60)
    print('ðŸ”„ Rozpoczynam przetwarzanie meczÃ³w...')
    print('='*60)
    
    rows = []
    qualifying_count = 0
    
    # KLUCZOWE: Na GitHub Actions uÅ¼ywaj krÃ³tszego interwaÅ‚u (mniej RAM)
    # Wykryj Å›rodowisko GitHub Actions
    is_github_actions = os.environ.get('GITHUB_ACTIONS') == 'true'
    if is_github_actions:
        RESTART_INTERVAL = 30  # GitHub Actions: restart co 30 meczÃ³w (oszczÄ™dnoÅ›Ä‡ pamiÄ™ci)
        print("ðŸ”§ Wykryto GitHub Actions - uÅ¼ywam skrÃ³conego interwaÅ‚u restartu (30 meczÃ³w)")
    else:
        RESTART_INTERVAL = 80  # Lokalnie: restart co 80 meczÃ³w
    
    CHECKPOINT_INTERVAL = 20  # Checkpoint co 20 meczÃ³w (zwiÄ™kszona czÄ™stotliwoÅ›Ä‡ dla bezpieczeÅ„stwa)
    
    for i, url in enumerate(urls, 1):
        if VERBOSE:
            print(f'\n[{i}/{len(urls)}] ðŸ” Przetwarzam: {url[:80]}...')
        else:
            # Prosty progress indicator
            print(f'\r[{i}/{len(urls)}] Przetwarzam...', end='', flush=True)
        try:
            # Wykryj sport z URL (tennis ma '/tenis/' w URLu)
            is_tennis = '/tenis/' in url.lower() or 'tennis' in url.lower()
            
            if is_tennis:
                # UÅ¼yj dedykowanej funkcji dla tenisa (ADVANCED)
                info = process_match_tennis(url, driver)
                rows.append(info)
                
                if info['qualifies']:
                    qualifying_count += 1
                    player_a_wins = info['home_wins_in_h2h_last5']
                    player_b_wins = info.get('away_wins_in_h2h', 0)
                    advanced_score = info.get('advanced_score', 0)
                    favorite = info.get('favorite', 'unknown')
                    
                    # OkreÅ›l kto jest faworytem
                    if favorite == 'player_a':
                        fav_name = info["home_team"]
                    elif favorite == 'player_b':
                        fav_name = info["away_team"]
                    else:
                        fav_name = "RÃ³wni"
                    
                    # Tryb normalny: krÃ³tka wiadomoÅ›Ä‡
                    if not VERBOSE:
                        print(f'\r[{i}/{len(urls)}] âœ… {info["home_team"]} vs {info["away_team"]} - Faworytem: {fav_name} ({advanced_score:.0f}/100)')
                    else:
                        # Tryb verbose: szczegÃ³Å‚y
                        print(f'   âœ… KWALIFIKUJE SIÄ˜! {info["home_team"]} vs {info["away_team"]}')
                        print(f'      Faworytem: {fav_name} (Score: {advanced_score:.1f}/100)')
                        print(f'      H2H: {player_a_wins}-{player_b_wins}')
                        
                        # PokaÅ¼ breakdown jeÅ›li dostÄ™pny
                        if 'score_breakdown' in info:
                            breakdown = info['score_breakdown']
                            print(f'      â””â”€ H2H:{breakdown.get("h2h_score", 0):.0f} | Rank:{breakdown.get("ranking_score", 0):.0f} | Form:{breakdown.get("form_score", 0):.0f} | Surface:{breakdown.get("surface_score", 0):.0f}')
                        
                        # PokaÅ¼ dodatkowe info
                        if info.get('ranking_a') and info.get('ranking_b'):
                            print(f'      Rankings: #{info["ranking_a"]} vs #{info["ranking_b"]}')
                        if info.get('surface'):
                            print(f'      Surface: {info["surface"]}')
                        
                else:
                    player_a_wins = info['home_wins_in_h2h_last5']
                    player_b_wins = info.get('away_wins_in_h2h', 0)
                    advanced_score = info.get('advanced_score', 0)
                    if VERBOSE:
                        print(f'   âŒ Nie kwalifikuje (H2H: {player_a_wins}-{player_b_wins}, Score: {advanced_score:.1f}/100)')
            else:
                # Sporty druÅ¼ynowe (football, basketball, etc.)
                info = process_match(url, driver, away_team_focus=args.away_team_focus)
                rows.append(info)
                
                if info['qualifies']:
                    qualifying_count += 1
                    h2h_count = info.get('h2h_count', 0)
                    win_rate = info.get('win_rate', 0.0)
                    home_form = info.get('home_form', [])
                    away_form = info.get('away_form', [])
                    
                    home_form_str = '-'.join(home_form) if home_form else 'N/A'
                    away_form_str = '-'.join(away_form) if away_form else 'N/A'
                    
                    # Wybierz co pokazaÄ‡ w zaleÅ¼noÅ›ci od trybu
                    if args.away_team_focus:
                        wins_count = info.get('away_wins_in_h2h_last5', 0)
                        team_name = info['away_team']
                    else:
                        wins_count = info['home_wins_in_h2h_last5']
                        team_name = info['home_team']
                    
                    # Tryb normalny: krÃ³tka wiadomoÅ›Ä‡
                    if not VERBOSE:
                        print(f'\r[{i}/{len(urls)}] âœ… {info["home_team"]} vs {info["away_team"]} - {team_name} ({wins_count}/{h2h_count} = {win_rate*100:.0f}%)')
                    else:
                        # Tryb verbose: szczegÃ³Å‚y
                        print(f'   âœ… KWALIFIKUJE SIÄ˜! {info["home_team"]} vs {info["away_team"]}')
                        print(f'      ZespÃ³Å‚ fokusowany: {team_name}')
                        print(f'      H2H: {wins_count}/{h2h_count} ({win_rate*100:.0f}%)')
                        if home_form or away_form:
                            print(f'      Forma: {info["home_team"]} [{home_form_str}] | {info["away_team"]} [{away_form_str}]')
                            
                        # PokaÅ¼ szczegÃ³Å‚y H2H dla kwalifikujÄ…cych siÄ™
                        if info['h2h_last5']:
                            print(f'      Ostatnie H2H:')
                            for idx, h2h in enumerate(info['h2h_last5'][:5], 1):
                                print(f'        {idx}. {h2h.get("home", "?")} {h2h.get("score", "?")} {h2h.get("away", "?")}')
                else:
                    h2h_count = info.get('h2h_count', 0)
                    win_rate = info.get('win_rate', 0.0)
                    if VERBOSE:
                        if h2h_count > 0:
                            if args.away_team_focus:
                                wins_count = info.get('away_wins_in_h2h_last5', 0)
                            else:
                                wins_count = info['home_wins_in_h2h_last5']
                            print(f'   âŒ Nie kwalifikuje ({wins_count}/{h2h_count} = {win_rate*100:.0f}%)')
                        else:
                            print(f'   âš ï¸  Brak H2H')
                
        except Exception as e:
            if VERBOSE:
                print(f'   âš ï¸  BÅ‚Ä…d: {e}')
        
        # AUTO-RESTART przeglÄ…darki co N meczÃ³w (zapobiega crashom)
        if i % RESTART_INTERVAL == 0 and i < len(urls):
            print(f'\nðŸ”„ AUTO-RESTART: Restartowanie przeglÄ…darki po {i} meczach...')
            print(f'   âœ… Przetworzone dane ({len(rows)} meczÃ³w) sÄ… bezpieczne w pamiÄ™ci!')
            try:
                driver.quit()
                # WymuÅ› garbage collection dla zwolnienia pamiÄ™ci (waÅ¼ne na GitHub Actions)
                gc.collect()
                time.sleep(2)
                driver = start_driver(headless=args.headless)
                print(f'   âœ… PrzeglÄ…darka zrestartowana! KontynuujÄ™ od meczu {i+1}...\n')
            except Exception as e:
                print(f'   âš ï¸  BÅ‚Ä…d restartu: {e}')
                gc.collect()  # WyczyÅ›Ä‡ pamiÄ™Ä‡ mimo bÅ‚Ä™du
                driver = start_driver(headless=args.headless)
        
        # Rate limiting - adaptacyjny (zoptymalizowany)
        elif i < len(urls):
            delay = 0.8 + (i % 3) * 0.3  # Zmniejszone z 1.0+0.5 na 0.8+0.3
            time.sleep(delay)

    driver.quit()

    # WyczyÅ›Ä‡ progress indicator z trybu normalnego
    if not VERBOSE:
        print()  # Nowa linia po progress indicator
    
    # Zapisywanie wynikÃ³w
    print('\n' + '='*60)
    print('ðŸ’¾ Zapisywanie wynikÃ³w...')
    print('='*60)
    
    os.makedirs('outputs', exist_ok=True)
    
    # Nazwa pliku z opcjonalnym sufixem
    suffix = f'_{args.output_suffix}' if args.output_suffix else ''
    if args.sports and len(args.sports) == 1:
        suffix = f'_{args.sports[0]}{suffix}'
    
    # Dodaj sufiks dla trybu away_team_focus
    if args.away_team_focus:
        suffix = f'{suffix}_AWAY_FOCUS'
    
    outfn = os.path.join('outputs', f'livesport_h2h_{args.date}{suffix}.csv')

    # Przygotowanie DataFrame
    df = pd.DataFrame(rows)
    
    # Konwersja h2h_last5 (lista sÅ‚ownikÃ³w) na string dla CSV
    if 'h2h_last5' in df.columns:
        df['h2h_last5'] = df['h2h_last5'].apply(lambda x: str(x) if x else '')
    
    # Konwersja all_odds (sÅ‚ownik) na JSON string dla CSV (NOWE V3)
    if 'all_odds' in df.columns:
        import json
        df['all_odds'] = df['all_odds'].apply(lambda x: json.dumps(x, ensure_ascii=False) if x else '')
    
    # Konwersja bookmakers_found (lista) na string dla CSV (NOWE V3)
    if 'bookmakers_found' in df.columns:
        df['bookmakers_found'] = df['bookmakers_found'].apply(lambda x: ', '.join(x) if isinstance(x, list) else str(x) if x else '')
    
    df.to_csv(outfn, index=False, encoding='utf-8-sig')

    # NOWE V3: Zapisz do bazy danych SQLite (dla aplikacji webowej)
    if DB_AVAILABLE and rows:
        try:
            print('\nðŸ’¾ Zapisywanie do bazy danych...')
            db = MatchDatabase()
            inserted = db.insert_matches_batch(rows)
            print(f'âœ… Zapisano {inserted}/{len(rows)} meczÃ³w do bazy danych')
            
            # PokaÅ¼ statystyki bazy
            stats = db.get_stats()
            print(f'ðŸ“Š Statystyki bazy danych:')
            print(f'   Wszystkich meczÃ³w: {stats["total_matches"]}')
            print(f'   KwalifikujÄ…cych siÄ™: {stats["qualifying_matches"]}')
            print(f'   SportÃ³w: {stats["unique_sports"]}')
            print(f'   Ostatnia aktualizacja: {stats["last_update"]}')
        except Exception as e:
            print(f'âš ï¸ BÅ‚Ä…d zapisu do bazy danych: {e}')

    # NOWE V4: WysyÅ‚ka danych do aplikacji UI (Heroku/Railway)
    if args.app_url and rows:
        try:
            print('\nðŸ”— KROK 4/4: WysyÅ‚anie danych do aplikacji UI...')
            print('='*70)
            from app_integrator import AppIntegrator
            
            integrator = AppIntegrator(app_url=args.app_url, api_key=args.app_api_key)
            
            # Test poÅ‚Ä…czenia
            print(f'\nðŸ” TestujÄ™ poÅ‚Ä…czenie z aplikacjÄ…...')
            print(f'   URL: {args.app_url}')
            if integrator.test_connection():
                print(f'   âœ… PoÅ‚Ä…czenie dziaÅ‚a!')
            else:
                print(f'   âš ï¸  Nie udaÅ‚o siÄ™ poÅ‚Ä…czyÄ‡, ale prÃ³bujÄ™ wysÅ‚aÄ‡ dane...')
            
            # WysyÅ‚ka danych
            print(f'\nðŸ“¤ WysyÅ‚am dane do aplikacji...')
            sport = args.sports[0] if args.sports else 'unknown'
            
            if integrator.send_matches(rows, args.date, sport):
                print(f'âœ… Synchronizacja z aplikacjÄ… ukoÅ„czona!')
            else:
                print(f'âš ï¸  Nie udaÅ‚o siÄ™ wysÅ‚aÄ‡ danych (ale scraping siÄ™ powiedÅ‚)')
                
        except ImportError:
            print(f'âš ï¸  app_integrator.py nie znaleziony - pomijam wysyÅ‚kÄ™ do aplikacji')
        except Exception as e:
            print(f'âš ï¸  BÅ‚Ä…d podczas wysyÅ‚ki do aplikacji: {e}')
    elif args.app_url and not rows:
        print(f'\nâš ï¸  Brak danych do wysÅ‚ania do aplikacji UI')
    elif not args.app_url:
        print(f'\nðŸ’¡ TIP: UÅ¼yj --app-url aby automatycznie wysyÅ‚aÄ‡ dane do aplikacji UI')

    # Podsumowanie
    print(f'\nðŸ“Š PODSUMOWANIE:')
    print(f'   Przetworzono meczÃ³w: {len(rows)}')
    print(f'   KwalifikujÄ…cych siÄ™: {qualifying_count} ({qualifying_count/len(rows)*100:.1f}%)' if rows else '   Brak danych')
    print(f'   Zapisano do: {outfn}')
    print('\nâœ¨ Gotowe!')


if __name__ == '__main__':
    main()

